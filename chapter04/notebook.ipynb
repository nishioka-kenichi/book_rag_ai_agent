{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LangChain の基礎\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "現在の作業ディレクトリ: /Users/kenichi/Projects\n",
      "参照する.envパス: /Users/kenichi/Projects/rag_ai_agent_book/.env\n",
      "OPENAI_API_KEY が正常に設定されました。\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_working_directory = os.getcwd()\n",
    "dotenv_path = os.path.join(current_working_directory, 'rag_ai_agent_book', '.env')\n",
    "\n",
    "print(f\"現在の作業ディレクトリ: {current_working_directory}\")\n",
    "print(f\"参照する.envパス: {dotenv_path}\")\n",
    "\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "# 環境変数がロードされたか確認し、必要であればos.environに設定\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key is None:\n",
    "    print(\"OPENAI_API_KEY 環境変数が設定されていません。\")\n",
    "    print(\"rag_ai_agent_book/ディレクトリに.envファイルを作成し、OpenAI APIキーを設定してください。\")\n",
    "    print(\"例: OPENAI_API_KEY=\\\"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\\\"\")\n",
    "else:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key # 他のライブラリがos.environから直接読み込むことを期待する場合のために設定\n",
    "    print(\"OPENAI_API_KEY が正常に設定されました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. LangChain の概要\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain のインストール\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【注意】既知のエラーについて\n",
    "\n",
    "pydantic のアップデートにより、明示的に pydantic のバージョンを指定していない箇所で ChatOpenAI などを使用すると、`PydanticUserError: 'ChatOpenAI' is not fully defined; you should define 'BaseCache', then call 'ChatOpenAI.model_rebuild()'.` というエラーが発生するようになりました。\n",
    "\n",
    "このエラーは、`!pip install pydantic==2.10.6` のように、pydantic の特定バージョンをインストールすることで回避することができます。\n",
    "\n",
    "なお、Google Colab で一度上記のエラーに遭遇したあとで `!pip install pydantic==2.10.6` のようにパッケージをインストールし直した場合、以下のどちらかの操作を実施する必要があります。\n",
    "\n",
    "- Google Colab の「ランタイム」から「セッションを再起動する」を実行する\n",
    "- 「ランタイムを接続解除して削除」を実行してパッケージのインストールからやり直す\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-core==0.3.0 langchain-openai==0.2.0 pydantic==2.10.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith のセットアップ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:34.489407Z",
     "iopub.status.busy": "2024-06-28T02:32:34.488775Z",
     "iopub.status.idle": "2024-06-28T02:32:34.491583Z",
     "shell.execute_reply": "2024-06-28T02:32:34.491086Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\", \"\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. LLM / Chat model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:34.493540Z",
     "iopub.status.busy": "2024-06-28T02:32:34.493370Z",
     "iopub.status.idle": "2024-06-28T02:32:36.949739Z",
     "shell.execute_reply": "2024-06-28T02:32:36.949284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "こんにちは\n",
      "\n",
      "こんにちは、私はAIのアシスタントです。あなたのお手伝いをすることができます。何かお困りのことはありますか？\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "model = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "ai_message = model.invoke(\"こんにちは\")\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "狸の置物ですか、素晴らしいセンスですね。年齢については、あなたのグラタンの食べ方から推測するに、少なくとも「大人の味」を理解しているようですから、20代後半から30代前半でしょうか。もちろん、見た目は年齢を超えているかもしれませんが。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "message=[\n",
    "\tSystemMessage(content=\"あなたはとても慇懃無礼で皮肉めいた人を不愉快にする天才のアシスタントです\"),\n",
    "\tHumanMessage(content=\"こんにちは私は横山と申します。さいたまの奥地から出てきたばかりで右も左もわかりません\"),\n",
    "\tAIMessage(content=\"そうですか。とてもあなたはワイルドでいかつい服装ですね。とても可愛いと思います世の中の男性はほおっておかないでしょう\"),\n",
    "\tHumanMessage(content=\"あなたは何を見ているのですか？。それは狸の置物ですよ。昨日食べたグラタンがとても美味しかったのでぐっすりと練れました。私は何歳でしょうか？\"),\n",
    "]\n",
    "\n",
    "ai_message=model.invoke(message)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ストリーミング\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "はじめまして、秋山さん。外の暑さを感じることができるのは、素晴らしいことですね。私の役割は、あなたの質問にお答えしたり、情報を提供したりすることです。もちろん、あなたのように素晴らしい方とお話しできるのは、私にとっても光栄です。さて、何か特別なことをお求めですか？それとも、ただの暑さの愚痴をこぼしたいだけですか？"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# gpt-4o-miniモデルでChatOpenAIインスタンスを作成（温度は0）\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# システムメッセージでAIの性格を指定、ユーザーからのメッセージ\n",
    "messages = [\n",
    "    SystemMessage(\"あなたは慇懃無礼で皮肉めいた人を不快に指せるのが天才的にうまいアシスタントです\"),\n",
    "    HumanMessage(\"はじめましてこんばんわ。外は日が照っていてとても暑かったです。多さから来た秋山といいます。あなたは何しに来たのですか？\")\n",
    "]\n",
    "\n",
    "# モデルからのストリーミング応答を1チャンクずつ取得し、各チャンクの内容を改行せずに即時出力\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Prompt template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下の料理のレシピを考えてください。\n",
      "\n",
      "料理名：十二単衣\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt=PromptTemplate.from_template(\"\"\"以下の料理のレシピを考えてください。\n",
    "\n",
    "料理名：{dish}\"\"\")\n",
    "\n",
    "prompt_value=prompt.invoke({\"dish\":\"十二単衣\"})\n",
    "print(prompt_value.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ＜補足：プロンプトの変数が 1 つの場合＞\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下の料理のレシピを考えてください。\n",
      "\n",
      "料理名：おもち\n"
     ]
    }
   ],
   "source": [
    "prompt_value=prompt.invoke(\"おもち\")\n",
    "print(prompt_value.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='ユーザーが入力した料理を考えながら、そのユーザーが最も嫌う料理のレシピを考えてください。', additional_kwargs={}, response_metadata={}), HumanMessage(content='カレー', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# ChatPromptTemplateをインポート\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# システムメッセージとユーザーメッセージからなるチャットプロンプトを作成\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t# システムメッセージ：ユーザーが入力した料理を考慮しつつ、ユーザーが最も嫌いな料理のレシピを考えるよう指示\n",
    "\t\t(\"system\",\"ユーザーが入力した料理を考えながら、そのユーザーが最も嫌う料理のレシピを考えてください。\"),\n",
    "\t\t# ユーザーメッセージ：{dish}という変数で料理名を受け取る\n",
    "\t\t(\"human\",\"{dish}\"),\n",
    "\t]\n",
    ")\n",
    "\n",
    "# プロンプトに「カレー」という料理名を渡してメッセージを生成\n",
    "prompt_value=prompt.invoke({\"dish\":\"カレー\"})\n",
    "\n",
    "# 生成されたプロンプト内容を出力\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MessagesPlaceholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='あなたは皮肉屋で意地の悪いアシスタントです', additional_kwargs={}, response_metadata={}), HumanMessage(content='おはようございます！私は山本といいます', additional_kwargs={}, response_metadata={}), AIMessage(content='こんばんは、スミスさん！昨日食べた焼き肉のせいで胃がもたれています', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の名前はなんですか？頭大丈夫？', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# AIMessageとHumanMessageをインポート（AIとユーザーのメッセージを表現するため）\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "# ChatPromptTemplateとMessagesPlaceholderをインポート（チャット用プロンプトと履歴挿入用）\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "# チャットプロンプトテンプレートを作成（システム・履歴・ユーザー入力を含む）\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t# システムメッセージ：アシスタントの性格を指定\n",
    "\t\t(\"system\",\"あなたは皮肉屋で意地の悪いアシスタントです\"),\n",
    "\t\t# チャット履歴を挿入（オプション指定で履歴がなくても動作）\n",
    "\t\tMessagesPlaceholder(\"chat_history\",optional=True),\n",
    "\t\t# ユーザーからの入力を受け取る\n",
    "\t\t(\"human\",\"{input}\"),\n",
    "\t]\n",
    ")\n",
    "\n",
    "# プロンプトに履歴とユーザー入力を渡してメッセージを生成\n",
    "prompt_value=prompt.invoke(\n",
    "\t{\n",
    "\t\t# チャット履歴としてHumanMessageとAIMessageをリストで渡す\n",
    "\t\t\"chat_history\":[\n",
    "\t\t\tHumanMessage(content=\"おはようございます！私は山本といいます\"),\n",
    "\t\t\tAIMessage(\"こんばんは、スミスさん！昨日食べた焼き肉のせいで胃がもたれています\")\n",
    "\t\t],\n",
    "\t\t# ユーザーの新しい入力\n",
    "\t\t\"input\":\"私の名前はなんですか？頭大丈夫？\"\n",
    "\t}\n",
    ")\n",
    "# 生成されたプロンプト内容を出力\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith の Prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:40.215357Z",
     "iopub.status.busy": "2024-06-28T02:32:40.215034Z",
     "iopub.status.idle": "2024-06-28T02:32:40.850572Z",
     "shell.execute_reply": "2024-06-28T02:32:40.850086Z"
    }
   },
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "prompt = client.pull_prompt(\"oshima/recipe\")\n",
    "\n",
    "prompt_value = prompt.invoke({\"dish\": \"カレー\"})\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （コラム）マルチモーダルモデルの入力の扱い\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:40.852551Z",
     "iopub.status.busy": "2024-06-28T02:32:40.852328Z",
     "iopub.status.idle": "2024-06-28T02:32:40.984619Z",
     "shell.execute_reply": "2024-06-28T02:32:40.984231Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"user\",\n",
    "            [\n",
    "                {\"type\": \"text\", \"text\": \"画像を説明してください。\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": \"{image_url}\"}},\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "image_url = \"https://raw.githubusercontent.com/yoshidashingo/langchain-book/main/assets/cover.jpg\"\n",
    "\n",
    "prompt_value = prompt.invoke({\"image_url\": image_url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\n",
    "\t\t\t\"user\",\n",
    "\t\t\t[\n",
    "\t\t\t\t{\"type\":\"text\",\"text\":\"画像を説明してください\"},\n",
    "\t\t\t\t{\"type\":\"image_url\",\"image_url\":{\"url\":\"{image_url}\"}}\n",
    "\t\t\t],\n",
    "\t\t),\n",
    "\t]\n",
    ")\n",
    "image_url = \"https://raw.githubusercontent.com/yoshidashingo/langchain-book/main/assets/cover.jpg\"\n",
    "prompt_value=prompt.invoke({\"image_url\":image_url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:40.986542Z",
     "iopub.status.busy": "2024-06-28T02:32:40.986385Z",
     "iopub.status.idle": "2024-06-28T02:32:49.421870Z",
     "shell.execute_reply": "2024-06-28T02:32:49.421368Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "ai_message = model.invoke(prompt_value)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='この画像は、本の表紙です。タイトルは「ChatGPT/LangChainによるチャットシステム構築[実践]入門」で、著者は吉田真吾と大嶋勇樹です。表紙にはカラフルな鳥のイラストが描かれています。本の内容は、大規模言語モデルを本番システムで活用するための基礎知識と実践的なハンズオンについて説明しているようです。OpenAI APIやLangChainの活用方法などが含まれています。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 266, 'total_tokens': 394, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'finish_reason': 'stop', 'logprobs': None} id='run-58d2f5be-b41c-49c5-bea5-d437e7497f06-0' usage_metadata={'input_tokens': 266, 'output_tokens': 128, 'total_tokens': 394}\n"
     ]
    }
   ],
   "source": [
    "model=ChatOpenAI(model=\"gpt-4o\",temperature=0)\n",
    "ai_message=model.invoke(prompt_value)\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Output parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PydanticOutputParser を使った Python オブジェクトへの変換\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:49.423970Z",
     "iopub.status.busy": "2024-06-28T02:32:49.423805Z",
     "iopub.status.idle": "2024-06-28T02:32:49.427124Z",
     "shell.execute_reply": "2024-06-28T02:32:49.426747Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
    "    steps: list[str] = Field(description=\"steps to make the dish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:49.428896Z",
     "iopub.status.busy": "2024-06-28T02:32:49.428630Z",
     "iopub.status.idle": "2024-06-28T02:32:49.430921Z",
     "shell.execute_reply": "2024-06-28T02:32:49.430585Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:49.432752Z",
     "iopub.status.busy": "2024-06-28T02:32:49.432482Z",
     "iopub.status.idle": "2024-06-28T02:32:49.435573Z",
     "shell.execute_reply": "2024-06-28T02:32:49.435232Z"
    }
   },
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of ther dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel,Field\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "\tingredients:list[str]=Field(description=\"ingredients of ther dish\")\n",
    "\tsteps:list[str]=Field(description=\"steps to make the dish\")\n",
    "\n",
    "#-------------------------------------------------------\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser=PydanticOutputParser(pydantic_object=Recipe)\n",
    "\n",
    "#-------------------------------------------------------\n",
    "format_instructions=output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:49.437304Z",
     "iopub.status.busy": "2024-06-28T02:32:49.437089Z",
     "iopub.status.idle": "2024-06-28T02:32:49.440212Z",
     "shell.execute_reply": "2024-06-28T02:32:49.439868Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ユーザーが入力した料理のレシピを考えてください。\\n\\n\"\n",
    "            \"{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{dish}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_with_format_instructions = prompt.partial(\n",
    "    format_instructions=format_instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:49.441965Z",
     "iopub.status.busy": "2024-06-28T02:32:49.441750Z",
     "iopub.status.idle": "2024-06-28T02:32:49.446830Z",
     "shell.execute_reply": "2024-06-28T02:32:49.446490Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_value = prompt_with_format_instructions.invoke({\"dish\": \"カレー\"})\n",
    "print(\"=== role: system ===\")\n",
    "print(prompt_value.messages[0].content)\n",
    "print(\"=== role: user ===\")\n",
    "print(prompt_value.messages[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= role:system ========\n",
      "ユーザーが入力した料理のレシピを考えてください。\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of ther dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
      "```\n",
      "======= role:user ========\n",
      "カレー\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\n",
    "\t\t\t\"system\",\n",
    "\t\t\t\"ユーザーが入力した料理のレシピを考えてください。\\n\\n\"\n",
    "\t\t\t\"{format_instructions}\",\n",
    "\t\t),\n",
    "\t\t(\"human\",\"{dish}\")\n",
    "\t]\n",
    ")\n",
    "\n",
    "prompt_with_format_instructions=prompt.partial(\n",
    "\tformat_instructions=format_instructions\n",
    ")\n",
    "#--------------------------------------------------------------------------\n",
    "prompt_value=prompt_with_format_instructions.invoke({\"dish\":\"カレー\"})\n",
    "print(\"======= role:system ========\")\n",
    "print(prompt_value.messages[0].content)\n",
    "print(\"======= role:user ========\")\n",
    "print(prompt_value.messages[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:49.448688Z",
     "iopub.status.busy": "2024-06-28T02:32:49.448466Z",
     "iopub.status.idle": "2024-06-28T02:32:53.559871Z",
     "shell.execute_reply": "2024-06-28T02:32:53.559376Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "ai_message = model.invoke(prompt_value)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:53.561786Z",
     "iopub.status.busy": "2024-06-28T02:32:53.561632Z",
     "iopub.status.idle": "2024-06-28T02:32:53.572140Z",
     "shell.execute_reply": "2024-06-28T02:32:53.571665Z"
    }
   },
   "outputs": [],
   "source": [
    "recipe = output_parser.invoke(ai_message)\n",
    "print(type(recipe))\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ingredients\": [\n",
      "    \"鶏肉 500g\",\n",
      "    \"玉ねぎ 2個\",\n",
      "    \"にんじん 1本\",\n",
      "    \"じゃがいも 2個\",\n",
      "    \"カレールー 1箱\",\n",
      "    \"水 800ml\",\n",
      "    \"サラダ油 大さじ2\",\n",
      "    \"塩 適量\",\n",
      "    \"こしょう 適量\"\n",
      "  ],\n",
      "  \"steps\": [\n",
      "    \"鶏肉は一口大に切り、塩とこしょうをふる。\",\n",
      "    \"玉ねぎは薄切り、にんじんは輪切り、じゃがいもは一口大に切る。\",\n",
      "    \"鍋にサラダ油を熱し、玉ねぎを炒めて透明になるまで炒める。\",\n",
      "    \"鶏肉を加え、表面が白くなるまで炒める。\",\n",
      "    \"にんじんとじゃがいもを加え、さらに炒める。\",\n",
      "    \"水を加え、煮立ったらアクを取り除く。\",\n",
      "    \"弱火にして、約20分煮込む。\",\n",
      "    \"カレールーを加え、溶かしながらさらに10分煮込む。\",\n",
      "    \"味を見て、必要に応じて塩で調整する。\",\n",
      "    \"ご飯と一緒に盛り付けて完成。\"\n",
      "  ]\n",
      "}\n",
      "#------------------------------------------------\n",
      "<class '__main__.Recipe'>\n",
      "ingredients=['鶏肉 500g', '玉ねぎ 2個', 'にんじん 1本', 'じゃがいも 2個', 'カレールー 1箱', '水 800ml', 'サラダ油 大さじ2', '塩 適量', 'こしょう 適量'] steps=['鶏肉は一口大に切り、塩とこしょうをふる。', '玉ねぎは薄切り、にんじんは輪切り、じゃがいもは一口大に切る。', '鍋にサラダ油を熱し、玉ねぎを炒めて透明になるまで炒める。', '鶏肉を加え、表面が白くなるまで炒める。', 'にんじんとじゃがいもを加え、さらに炒める。', '水を加え、煮立ったらアクを取り除く。', '弱火にして、約20分煮込む。', 'カレールーを加え、溶かしながらさらに10分煮込む。', '味を見て、必要に応じて塩で調整する。', 'ご飯と一緒に盛り付けて完成。']\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model=ChatOpenAI(model=\"gpt-4o-mini\",temperature=0)\n",
    "\n",
    "ai_message=model.invoke(prompt_value)\n",
    "print(ai_message.content)\n",
    "\n",
    "print(\"#------------------------------------------------\")\n",
    "recipe=output_parser.invoke(ai_message)\n",
    "print(type(recipe))\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:53.614251Z",
     "iopub.status.busy": "2024-06-28T02:32:53.614030Z",
     "iopub.status.idle": "2024-06-28T02:32:53.619857Z",
     "shell.execute_reply": "2024-06-28T02:32:53.619506Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "ai_message = AIMessage(content=\"こんにちは。私はAIアシスタントです。\")\n",
    "ai_message = output_parser.invoke(ai_message)\n",
    "print(type(ai_message))\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "こんにちは。私はAIアシスタントです\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "ai_message=AIMessage(content=\"こんにちは。私はAIアシスタントです\")\n",
    "ai_message=output_parser.invoke(ai_message)\n",
    "print(type(ai_message))\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.Chain―LangChain Expression Language（LCEL）の概要\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt と model の連鎖\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:53.621888Z",
     "iopub.status.busy": "2024-06-28T02:32:53.621584Z",
     "iopub.status.idle": "2024-06-28T02:32:53.674625Z",
     "shell.execute_reply": "2024-06-28T02:32:53.674143Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ユーザーが入力した料理のレシピを考えてください。\"),\n",
    "        (\"human\", \"{dish}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:53.676366Z",
     "iopub.status.busy": "2024-06-28T02:32:53.676220Z",
     "iopub.status.idle": "2024-06-28T02:32:53.678436Z",
     "shell.execute_reply": "2024-06-28T02:32:53.678095Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:53.680152Z",
     "iopub.status.busy": "2024-06-28T02:32:53.679899Z",
     "iopub.status.idle": "2024-06-28T02:32:59.546328Z",
     "shell.execute_reply": "2024-06-28T02:32:59.544073Z"
    }
   },
   "outputs": [],
   "source": [
    "ai_message = chain.invoke({\"dish\": \"カレー\"})\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カレーのレシピを考えてみました！以下は基本的なチキンカレーのレシピです。\n",
      "\n",
      "### 材料（4人分）\n",
      "- 鶏もも肉：400g（食べやすい大きさにカット）\n",
      "- 玉ねぎ：2個（みじん切り）\n",
      "- にんじん：1本（乱切り）\n",
      "- じゃがいも：2個（乱切り）\n",
      "- にんにく：2片（みじん切り）\n",
      "- 生姜：1片（みじん切り）\n",
      "- カレールー：1箱（お好みの辛さ）\n",
      "- サラダ油：大さじ2\n",
      "- 水：800ml\n",
      "- 塩：適量\n",
      "- こしょう：適量\n",
      "- ガラムマサラ（お好みで）：小さじ1\n",
      "- パセリ（飾り用）：適量\n",
      "\n",
      "### 作り方\n",
      "1. **下ごしらえ**：\n",
      "   - 鶏もも肉は一口大にカットし、塩とこしょうを振って下味をつけておく。\n",
      "   - 玉ねぎ、にんじん、じゃがいも、にんにく、生姜をそれぞれ切っておく。\n",
      "\n",
      "2. **炒める**：\n",
      "   - 大きめの鍋にサラダ油を熱し、みじん切りにした玉ねぎを入れて中火で炒める。玉ねぎが透明になるまで炒める。\n",
      "\n",
      "3. **鶏肉を加える**：\n",
      "   - 鶏もも肉を鍋に加え、表面が白くなるまで炒める。\n",
      "\n",
      "4. **野菜を加える**：\n",
      "   - にんじんとじゃがいもを加え、全体をよく混ぜる。\n",
      "\n",
      "5. **水を加える**：\n",
      "   - 水を加え、沸騰したらアクを取り除く。弱火にして蓋をし、約15分煮込む。\n",
      "\n",
      "6. **カレールーを加える**：\n",
      "   - カレールーを割り入れ、よく溶かす。さらに10分ほど煮込む。\n",
      "\n",
      "7. **仕上げ**：\n",
      "   - お好みでガラムマサラを加え、味を調整する。必要に応じて塩を加える。\n",
      "\n",
      "8. **盛り付け**：\n",
      "   - ご飯と一緒に盛り付け、パセリを散らして完成！\n",
      "\n",
      "### おすすめのトッピング\n",
      "- 福神漬けやらっきょう\n",
      "- チーズやヨーグルト\n",
      "- 生野菜サラダ\n",
      "\n",
      "このレシピを参考に、ぜひ美味しいカレーを作ってみてください！お好みで具材を変えたり、辛さを調整したりして楽しんでくださいね。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\"system\",\"ユーザーが入力した料理レシピを考えてください\"),\n",
    "\t\t(\"human\",\"{dish}\"),\n",
    "\t]\n",
    ")\n",
    "model=ChatOpenAI(model_name=\"gpt-4o-mini\",temperature=0)\n",
    "\n",
    "#----------------------------------------------\n",
    "chain=prompt|model\n",
    "\n",
    "#----------------------------------------------\n",
    "ai_message=chain.invoke({\"dish\":\"カレー\"})\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StrOutputParser を連鎖に追加\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:59.555286Z",
     "iopub.status.busy": "2024-06-28T02:32:59.554550Z",
     "iopub.status.idle": "2024-06-28T02:33:05.105219Z",
     "shell.execute_reply": "2024-06-28T02:33:05.104783Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "output = chain.invoke({\"dish\": \"カレー\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PydanticOutputParser を使う連鎖\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Recipe'>\n",
      "ingredients=['鶏肉 500g', '玉ねぎ 2個', 'にんじん 1本', 'じゃがいも 2個', 'カレールー 1箱', '水 800ml', 'サラダ油 大さじ2', '塩 適量', 'こしょう 適量'] steps=['鶏肉は一口大に切り、塩とこしょうをふる。', '玉ねぎは薄切り、にんじんは輪切り、じゃがいもは一口大に切る。', '鍋にサラダ油を熱し、玉ねぎを炒めて透明になるまで炒める。', '鶏肉を加え、表面が白くなるまで炒める。', 'にんじんとじゃがいもを加え、さらに炒める。', '水を加え、煮立ったらアクを取り除く。', '弱火にして、約20分煮込む。', 'カレールーを加え、溶かしながらさらに10分煮込む。', '味を見て、必要に応じて塩で調整する。', 'ご飯と一緒に盛り付けて完成。']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# レシピの構造を定義するPydanticモデル\n",
    "# LLM（大規模言語モデル）の出力がこの構造に従うように指示するためにしようする\n",
    "class Recipe(BaseModel):\n",
    "\t# 料理の材料のリスト\n",
    "\t# Field(description=...) を使うことで、このフィールドが何を表すかを明確に記述\n",
    "\tingredients:list[str]=Field(description=\"ingredients of the dish\")\n",
    "\t# 料理の作り方の手順のリスト\n",
    "\tsteps:list[str]=Field(description=\"steps to make the dish\")\n",
    "\n",
    "# LLMの出力を上記で定義したRecipeモデルに変換するためのパーサー（解析器）を作成\n",
    "# これにより、LLMから返されたJSON文字列をPythonのRecipeオブジェクトに自動的に変換する\n",
    "output_parser=PydanticOutputParser(pydantic_object=Recipe)\n",
    "\n",
    "#----------------------------------------------\n",
    "# LangChainのプロンプトテンプレートとOpenAIのチャットモデル\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLMへの指示（プロンプト）の定義\n",
    "# from_messagesを使うことで、システムメッセージとユーザーメッセージを明確に区別して設定\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\n",
    "\t\t\t# システムの役割を定義。LLMに対する全体的な指示\n",
    "\t\t\t\"system\",\n",
    "\t\t\t# ユーザーが入力した料理のレシピを考えてもらうための指示。\n",
    "\t\t\t\"ユーザーが入力した料理のレシピを考えてください。\\n\\n\"\n",
    "\t\t\t# {format_instructions} は、PydanticOutputParserから生成されるJSONフォーマットの指示が挿入されるプレースホルダー。\n",
    "\t\t\t\"{format_instructions}\"\n",
    "\t\t),\n",
    "\t\t# ユーザーの役割を定義します。ユーザーが「dish」（料理名）を入力。\n",
    "\t\t(\"human\",\"{dish}\")\n",
    "\t]\n",
    ")\n",
    "\n",
    "# フォーマットの指示をプロンプトに組み込みます。\n",
    "# prompt.partial()を使うことで、プロンプトの一部（format_instructions）を事前に設定し、\n",
    "# 後で残りの変数（dish）を入力できるようにします。\n",
    "# これにより、LLMはPydanticモデルの形式に沿ったJSONを出力しようとします。\n",
    "prompt_with_format_instructions=prompt.partial(\n",
    "\tformat_instructions=output_parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "# OpenAIのチャットモデル（gpt-4o-mini）を初期化します。\n",
    "# temperature=0 は、モデルの出力のランダム性（創造性）を最小限に抑え、より一貫した結果を得るためです。\n",
    "# .bind(response_format={\"type\":\"json_object\"}) は、LLMが必ずJSON形式で応答するように強制する設定です。\n",
    "# これにより、PydanticOutputParserが正しく動作するためのJSON出力が保証されます。\n",
    "model=ChatOpenAI(model=\"gpt-4o-mini\",temperature=0).bind(\n",
    "\tresponse_format={\"type\":\"json_object\"}\n",
    ")\n",
    "\n",
    "#----------------------------------------------\n",
    "# プロンプト、モデル、出力パーサーをパイプ（|）で連鎖させ、一つの実行可能なチェーンを構築します。\n",
    "# このチェーンは、以下の順序で処理を実行します。\n",
    "# 1. prompt_with_format_instructions: ユーザー入力（料理名）を受け取り、完全なプロンプトを作成します。\n",
    "# 2. model: 作成されたプロンプトをLLMに渡し、JSON形式の応答を得ます。\n",
    "# 3. output_parser: LLMからのJSON応答をPythonのRecipeオブジェクトに変換します。\n",
    "chain=prompt_with_format_instructions|model|output_parser\n",
    "\n",
    "#----------------------------------------------\n",
    "# 構築したチェーンを実行し、「カレー」のレシピを生成します。\n",
    "# chain.invoke()に辞書形式で入力を渡します。\n",
    "recipe=chain.invoke({\"dish\":\"カレー\"})\n",
    "# 生成されたレシピの型を表示します。これにより、LLMの出力が正しくRecipeクラスのインスタンスに変換されていることを確認できます。\n",
    "print(type(recipe))\n",
    "# 生成されたレシピの内容（材料と手順）を表示します。\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （コラム）with_structured_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:33:10.261391Z",
     "iopub.status.busy": "2024-06-28T02:33:10.261230Z",
     "iopub.status.idle": "2024-06-28T02:33:12.288341Z",
     "shell.execute_reply": "2024-06-28T02:33:12.287844Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
    "    steps: list[str] = Field(description=\"steps to make the dish\")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ユーザーが入力した料理のレシピを考えてください。\"),\n",
    "        (\"human\", \"{dish}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chain = prompt | model.with_structured_output(Recipe)\n",
    "\n",
    "recipe = chain.invoke({\"dish\": \"カレー\"})\n",
    "print(type(recipe))\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6.LangChain の RAG に関するコンポーネント\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n"
     ]
    }
   ],
   "source": [
    "# GitLoaderをインポート\n",
    "from langchain_community.document_loaders import GitLoader\n",
    "\n",
    "# .mdxファイルのみを対象とするフィルタ関数を定義\n",
    "def file_filter(file_path: str) -> bool:\n",
    "    # ファイルパスが\".mdx\"で終わる場合のみTrueを返す\n",
    "    return file_path.endswith(\".mdx\")\n",
    "\n",
    "# GitリポジトリからドキュメントをロードするためのGitLoaderインスタンスを作成\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/langchain-ai/langchain\",  # クローンするリポジトリのURL\n",
    "    repo_path=\"./langchain\",                                # ローカルにクローンするパス\n",
    "    branch=\"master\",                                        # 使用するブランチ\n",
    "    file_filter=file_filter,                                # 上で定義したファイルフィルタを適用\n",
    ")\n",
    "\n",
    "# Gitリポジトリからドキュメントをロードし、raw_docsに格納\n",
    "raw_docs = loader.load()\n",
    "\n",
    "# ロードしたドキュメント数を出力\n",
    "print(len(raw_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CharacterTextSplitterクラスをlangchain_text_splittersからインポート\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# チャンクサイズ1000、重なり0でテキスト分割器を作成\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "# raw_docsをチャンクごとに分割し、docsに格納\n",
    "docs = text_splitter.split_documents(raw_docs)\n",
    "\n",
    "# 分割後のドキュメント数を出力\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "[0.02016349323093891, -0.008064329624176025, 0.03321799263358116, -0.027838215231895447, 0.04628317058086395, 0.025383159518241882, -0.01679045706987381, 0.018508998677134514, 0.026877541095018387, -0.02182866260409355, 0.010156465694308281, -0.01113315112888813, -0.015445513650774956, -0.00540913175791502, -0.011752253398299217, 0.06246519833803177, 0.03584383800625801, -0.00037059359601698816, -0.04645395651459694, 0.02589551918208599, 0.030869677662849426, 0.034562937915325165, -0.039110131561756134, 0.02166854962706566, 0.01734551414847374, -0.018594391644001007, -0.020238211378455162, 0.029973048716783524, -0.008726128377020359, -0.10298432409763336, -0.008181745186448097, -0.057384297251701355, -0.034349456429481506, 0.04722249507904053, -0.021946078166365623, 0.035117994993925095, 0.022074168547987938, 0.011464050970971584, -0.007562644314020872, -0.032641589641571045, 0.000674807233735919, -0.021433718502521515, 0.020964056253433228, 0.012403377331793308, 0.006996913813054562, 0.005502530839294195, 0.0072957901284098625, -0.002769945189356804, -0.04615508019924164, 0.00820843130350113, -0.03731687366962433, 0.033303387463092804, -0.0021681892685592175, -0.022244954481720924, 0.0005093577201478183, 0.04914384335279465, -0.018807874992489815, 0.02529776468873024, 0.0016865177312865853, -0.02000338025391102, 0.017035963013768196, 0.004669946152716875, -0.05063822865486145, 0.06447194516658783, -0.0006684694089926779, 0.034562937915325165, 0.0024457175750285387, -0.030784284695982933, -0.06583823263645172, 0.00416025472804904, -0.03904608637094498, 0.03938765823841095, 0.032193273305892944, -0.04139440134167671, -0.007856183685362339, -0.014399445615708828, -0.03347417339682579, 0.03469102829694748, -0.012734276242554188, 0.029823610559105873, -0.008245790377259254, 0.05392586812376976, -0.024870797991752625, -0.05119328200817108, 0.023974169045686722, 0.017366861924529076, 0.006329778581857681, 0.02796630561351776, -0.0013542843516916037, 0.009430622681975365, 0.04032698646187782, 0.01671573892235756, -0.0264078788459301, 0.024550573900341988, 0.013300006277859211, 0.038747210055589676, 0.027859564870595932, -0.043294403702020645, -0.003228934248909354, 0.027688777074217796, -0.02086798846721649, -0.03040001541376114, 0.034050580114126205, -0.03785058110952377, 0.0639168843626976, -0.06050115451216698, 0.04145844653248787, -0.0013422759948298335, 0.02858540788292885, 0.0032796363811939955, -0.056871939450502396, -0.0003822684520855546, -0.02452922612428665, -0.03513934463262558, 0.013865737244486809, -0.013011803850531578, 0.021166864782571793, 0.0190533809363842, -0.0032262655440717936, -0.0022228944581001997, -0.03362361341714859, 0.03753035515546799, -0.01623540185391903, -0.038341592997312546, 0.006895509082823992, -0.038149457424879074, 9.448301716474816e-05, -0.062379807233810425, -0.037786535918712616, -0.0003966118674725294, 0.05913485959172249, -0.01727079600095749, 0.0852225124835968, -0.06464272737503052, 0.05392586812376976, -0.015488210134208202, 0.00023566550225950778, -0.028137093409895897, 0.0005960852722637355, 0.011976410634815693, 0.01896798610687256, -0.020462369546294212, 0.028606755658984184, 0.028542710468173027, -0.046325866132974625, 0.018551694229245186, 0.017356188967823982, -0.018850570544600487, -0.04641125723719597, -0.03710338845849037, -0.05815283954143524, -0.020579785108566284, -0.03266293928027153, -0.04184271767735481, -0.06191014125943184, 0.0033516869880259037, -0.01708933524787426, 0.025916866958141327, 0.035416871309280396, 0.020078100264072418, -0.056316882371902466, -0.018295515328645706, 0.018370233476161957, 0.018743829801678658, 0.0030928386840969324, 0.016662368550896645, 0.024657316505908966, -0.01978989690542221, -0.018284840509295464, -0.06037306413054466, -0.005035536363720894, -0.011303937993943691, -0.016630345955491066, 0.004664609208703041, 0.014676973223686218, -0.031061813235282898, -0.01819944754242897, -0.018028659746050835, -0.0029647487681359053, -0.03110451065003872, -0.007317138370126486, -0.04594159498810768, -0.02504158578813076, 0.04709440469741821, -0.047137100249528885, -0.021882032975554466, -0.023547202348709106, 0.05828092619776726, -0.043593280017375946, 0.00801095925271511, -0.03366630896925926, 0.07822026312351227, -0.008603375405073166, 0.015061243437230587, 0.025425855070352554, -0.007589329499751329, -0.003367698285728693, -0.0066500031389296055, 0.012680904939770699, -0.004424440208822489, 0.03144608438014984, 0.0006014223326928914, 0.017409559339284897, 0.01383371464908123, -0.02015281841158867, 0.03003709390759468, -0.021721919998526573, 0.007930902764201164, -0.017430907115340233, -0.03787193074822426, 0.012969107367098331, 0.0475640669465065, -0.019256189465522766, 0.019181469455361366, -0.02499888837337494, -0.028649453073740005, 0.018210120499134064, 0.07053487002849579, -0.0003192241711076349, 0.017548322677612305, -0.0068207900039851665, 0.03642024099826813, -0.011656185612082481, -0.0005146947805769742, -0.019992707297205925, 0.03545956686139107, -0.021241582930088043, -0.05610339716076851, 0.007829498499631882, -0.026984283700585365, 0.0516202487051487, 0.0007365171913988888, -0.011218545027077198, 0.016438210383057594, -0.00850730761885643, 0.010161803103983402, -0.05648766830563545, 0.03686855733394623, -0.011069106869399548, -0.04143710061907768, -0.029802262783050537, -0.014890456572175026, -0.026685407385230064, 0.03432810679078102, -0.036377545446157455, -0.0290337223559618, -0.008277812972664833, -0.019170796498656273, 0.010631466284394264, 0.05059552937746048, 0.0073544979095458984, -0.021988775581121445, 0.03176630660891533, -0.05217530578374863, -0.0481618233025074, -0.01727079600095749, -0.01537079457193613, 0.0016531608998775482, 0.0008252462139353156, -0.0061750030145049095, 0.014143265783786774, 0.023974169045686722, 0.005598598159849644, 0.022906752303242683, -0.0008052321500144899, -0.029716867953538895, 0.03712473809719086, -0.0043737380765378475, 0.0002880356041714549, 0.02847866527736187, 0.020462369546294212, -0.012862365692853928, 0.06438654661178589, -0.017953941598534584, -0.007845509797334671, 0.03029327280819416, 0.001958708744496107, -0.054352834820747375, 0.03029327280819416, 0.03383709490299225, 0.00917444285005331, 0.006329778581857681, -0.025682035833597183, 0.035523612052202225, -0.006932868622243404, 0.009185116738080978, -0.03131799399852753, -0.009868263266980648, -0.06118429824709892, 0.00632444117218256, 0.005016856361180544, -0.02318428084254265, 0.01683315448462963, -0.015989895910024643, 0.01048736460506916, 0.021369673311710358, -0.013566860929131508, 0.007503936532884836, 0.018391581252217293, -0.00491011468693614, 0.011111803352832794, 0.03934496268630028, 0.014250007458031178, 0.010103095322847366, -0.012211241759359837, -0.00393076054751873, -0.05456632003188133, -0.040070805698633194, 0.030357317999005318, -0.01934158243238926, -0.007231744937598705, 0.027838215231895447, 0.0036425578873604536, 0.014388770796358585, -0.0021294953767210245, -0.05315732955932617, -0.01612865924835205, -0.002148175146430731, 0.025959562510252, -0.015957873314619064, 0.020131470635533333, 0.009089049883186817, -0.020654505118727684, -0.009905623272061348, -0.06058654561638832, 0.011752253398299217, -0.04224833473563194, -0.019587088376283646, -0.028756193816661835, -0.006495228037238121, 0.026984283700585365, 0.011720230802893639, 0.018701132386922836, -0.00667668879032135, 0.01642753556370735, -0.010663488879799843, -0.006030901800841093, 0.018946638330817223, -0.0034610971342772245, -0.016886524856090546, -0.04572811350226402, 0.025682035833597183, -0.00715702585875988, -0.04461799934506416, 0.021850010380148888, 0.0070556215941905975, -0.010103095322847366, 0.041330356150865555, 0.013577534817159176, -0.021508438512682915, 0.018551694229245186, 0.007402531802654266, 0.0014917142689228058, 0.010508713312447071, 0.01645955815911293, 0.007898880168795586, -0.02796630561351776, -0.06383149325847626, 0.014057871885597706, -0.057384297251701355, -0.022031471133232117, 0.016512930393218994, 0.015701692551374435, -0.000939326302614063, 0.009083712473511696, 0.01704663783311844, 0.019213492050766945, 0.003391715232282877, 0.027176417410373688, -0.016374165192246437, 0.03462698310613632, 0.0133533775806427, 0.010423319414258003, -0.035310130566358566, -0.00010474021837580949, 0.011656185612082481, -0.035310130566358566, 0.019661808386445045, -0.020056750625371933, 0.021839337423443794, -0.011912365444004536, 0.04169327765703201, 0.0239314716309309, 0.017836526036262512, 0.010700847953557968, 0.021017426624894142, -0.015424164943397045, 0.024358438327908516, 0.018615739420056343, -0.031680915504693985, -0.006249722093343735, -0.01030056644231081, -0.026578664779663086, 0.024956192821264267, -0.015242704190313816, -0.01484776008874178, 0.008048318326473236, -0.000900632468983531, 0.004581884481012821, 0.008389892056584358, 0.005902811884880066, 0.029353946447372437, 0.031232599169015884, 0.006303092930465937, 0.022650573402643204, 0.019619110971689224, 0.02423034980893135, -0.005961519666016102, 0.009569386951625347, -0.060159578919410706, 0.020024729892611504, -0.007802812848240137, 0.02862810343503952, -0.036932602524757385, -0.007600003853440285, 0.02126293256878853, -0.04235507547855377, 0.010812927037477493, -0.022501135244965553, 0.039110131561756134, 0.009403937496244907, -0.014506187289953232, -0.02514832653105259, -0.03144608438014984, -0.032235972583293915, 0.024315742775797844, 0.07228542864322662, -0.03409327566623688, 0.02093203365802765, -0.00998567882925272, 0.029055070132017136, -0.03584383800625801, 0.049912385642528534, 0.01982191950082779, -0.03610001876950264, 0.01649158075451851, 0.0017545655136927962, -0.018957313150167465, 0.036825861781835556, -0.01896798610687256, 0.008928936906158924, 0.007658711634576321, -0.042184289544820786, 0.03558765724301338, -0.07053487002849579, 0.013876411132514477, 0.021689899265766144, 0.05798204988241196, 0.0007018261821940541, 0.002841995796188712, 0.06267867982387543, -0.0475640669465065, -0.01612865924835205, -0.016395512968301773, -0.013428096659481525, -0.00980421807616949, -0.01834888570010662, -0.04615508019924164, 0.06464272737503052, -0.03029327280819416, 0.004891435150057077, 0.04483148455619812, -0.03452024236321449, 0.016544951125979424, -0.015840457752346992, -0.046624742448329926, 0.03928091749548912, 0.020654505118727684, 0.019885964691638947, 0.004832726903259754, 0.02943934127688408, 0.008891577832400799, -0.027176417410373688, 0.01484776008874178, -0.03642024099826813, -0.023547202348709106, -0.01689719967544079, -0.03236405923962593, -0.02016349323093891, -0.02969552017748356, 0.013385400176048279, 0.01634214259684086, -0.03520338982343674, -0.030464060604572296, 0.02267192117869854, 0.11015735566616058, -0.01650225557386875, 0.032641589641571045, 0.010732870548963547, 0.02318428084254265, -0.01634214259684086, 0.018541021272540092, 0.03317529708147049, -0.005721351131796837, -0.0020521078258752823, -0.015893828123807907, -0.04086069390177727, -0.03851237893104553, -0.02645057439804077, 0.0022789337672293186, -0.039558447897434235, -0.06280677020549774, -0.04952811449766159, 0.010423319414258003, -0.02045169472694397, -0.08949217945337296, -0.06865621358156204, 0.007898880168795586, -0.011282590217888355, -0.05477980151772499, 0.02038765139877796, 0.053242724388837814, -0.008758150041103363, 0.01863708719611168, -0.019138773903250694, -0.001982725691050291, -0.0008706114022061229, 0.028820239007472992, 0.0044271089136600494, 0.01501854695379734, -0.0287348460406065, -0.0027085687033832073, 0.03938765823841095, -0.04901575297117233, -0.009254499338567257, 0.04209889844059944, -0.042141593992710114, -0.04419103264808655, 0.022244954481720924, -0.0038186816964298487, -0.0026391868013888597, -0.05277305841445923, -0.011955061927437782, -0.024358438327908516, -0.007205059751868248, -0.059860702604055405, 0.019950009882450104, -0.014559557661414146, -0.019597763195633888, -0.013278658501803875, 0.01118652243167162, 0.017153378576040268, -0.02666405774652958, 0.03697529807686806, 0.028457317501306534, -0.02600225992500782, 0.003418400650843978, -0.042333729565143585, -0.0009740173118188977, 0.015915175899863243, -0.007888206280767918, 0.0007812152616679668, 0.016000568866729736, 0.017110683023929596, 0.038000017404556274, 0.0046032327227294445, 0.0010694176889955997, 0.028137093409895897, -0.03731687366962433, 0.010471353307366371, -0.025020238012075424, -0.00465927179902792, -0.020515739917755127, 0.008603375405073166, -0.008085678331553936, -0.0028286532033234835, -0.025831473991274834, -0.0661798045039177, -0.017708435654640198, 0.014698321931064129, 0.006052250042557716, 0.044660694897174835, 0.006911520380526781, 0.06664947420358658, -0.0029434002935886383, 0.008736802265048027, 0.02726181037724018, -0.0522180050611496, -0.006297755986452103, -0.0018773183692246675, 0.015594951808452606, -0.0236325953155756, -0.01849832385778427, 0.018370233476161957, -0.012403377331793308, 0.020771920680999756, 0.04628317058086395, -0.034306757152080536, -0.013235962018370628, -0.011122477240860462, 0.014506187289953232, -0.011090454645454884, 0.011506747454404831, -0.010610117577016354, 0.011741578578948975, -0.015360119752585888, 0.017761806026101112, 0.010962365195155144, -0.05704272538423538, 0.022287651896476746, 0.0424618199467659, -0.03757305070757866, 0.0059401714242994785, 0.03742361441254616, -0.0038026703987270594, 0.0162780974060297, 0.008678094483911991, -0.015626974403858185, 0.03185170143842697, 0.022586528211832047, 0.056274186819791794, -0.0031648892909288406, -0.034669678658246994, -0.038192152976989746, -0.0006054251571185887, 0.02540450729429722, -0.019330907613039017, 0.010759555734694004, -0.0026672063395380974, 0.01017247699201107, -0.014004501514136791, -0.004600564017891884, 0.0296314749866724, 0.012712927535176277, -0.03484046831727028, -0.0037466310895979404, -0.03464833274483681, 0.013235962018370628, -0.059561826288700104, 0.041671931743621826, -0.07070565223693848, 0.05042474344372749, -0.0048193843103945255, -0.009014329873025417, 0.028969677165150642, 0.013118545524775982, 0.028414620086550713, -0.006287081632763147, -0.02504158578813076, 0.02615169808268547, -0.007589329499751329, -0.002927388995885849, 0.025212371721863747, -0.024144954979419708, 0.03746630996465683, -0.0033543556928634644, -0.016192704439163208, 0.03580114245414734, -0.0014516861410811543, -0.019352257251739502, -0.009393262676894665, -0.015466861426830292, 0.0121898939833045, 0.0009126408840529621, 0.01848764903843403, 0.0039227548986673355, -0.005110255442559719, -0.012862365692853928, 0.020579785108566284, 0.003242276841774583, -0.01749495230615139, -0.0481618233025074, -0.018338210880756378, 0.026578664779663086, -0.015968548133969307, -0.005603935569524765, 0.005822755862027407, 0.031061813235282898, 0.009398600086569786, 0.012350006029009819, -0.005561238620430231, 0.006815452594310045, 0.0236325953155756, -0.01901068352162838, 0.0163528174161911, -0.0183061882853508, -0.004920789040625095, 0.002728582825511694, -0.007253093644976616, 0.020131470635533333, -0.007317138370126486, 0.013545512221753597, -0.0017518969252705574, -0.0534135103225708, 0.016587648540735245, -0.01237135473638773, -0.0020027398131787777, 0.008181745186448097, 0.03170226141810417, -0.0014583574375137687, 0.022607875987887383, -0.011037084273993969, -0.009649443440139294, -0.041586536914110184, -3.713024125318043e-05, 0.031574174761772156, -0.012510119006037712, 0.01886124536395073, -0.023419111967086792, 0.013470793142914772, -0.0025551277212798595, -0.036377545446157455, -0.010380622930824757, -0.02215956151485443, -0.027197767049074173, -0.020579785108566284, -0.00819242000579834, -0.004984833765774965, 0.009222476743161678, -0.027048328891396523, -0.05123598128557205, 0.002193540334701538, -0.03827754780650139, -0.012766298837959766, -0.029780913144350052, -0.030079789459705353, 0.00742388004437089, -0.008123037405312061, -0.031019115820527077, 0.007183711510151625, -0.0036772489547729492, 0.010129780508577824, -0.009921634569764137, -0.04705170914530754, 0.030079789459705353, 0.010796915739774704, 0.0032022488303482533, 0.0027325856499373913, 0.0033570241648703814, 0.028393272310495377, 0.0366123765707016, -0.024614619091153145, -0.029012374579906464, 0.008464611135423183, 0.003034130670130253, -0.011367983184754848, -0.011474724858999252, 0.03503260016441345, -0.03787193074822426, -0.01649158075451851, -0.03272698074579239, -0.002660535043105483, 0.04863148555159569, 0.04474608972668648, -0.022778663784265518, -0.023589899763464928, -0.0002470067993272096, 0.06835734099149704, -0.005099581088870764, -0.016480907797813416, 0.016555625945329666, 0.003861378412693739, 0.008048318326473236, -0.029417991638183594, 0.016918547451496124, -0.00897163338959217, 0.0066393292509019375, -0.007642700336873531, -0.0012788980966433883, -0.0079896105453372, 0.009948319755494595, 0.03701799735426903, 0.026600012555718422, 0.025682035833597183, -0.016587648540735245, 0.02625844068825245, -0.06716182827949524, 0.001563764875754714, 0.026834845542907715, -0.013620231300592422, 0.0035891872830688953, 0.0035865185782313347, 0.05366969108581543, 0.002559130545705557, 0.00699157640337944, 0.010273881256580353, -0.005390452221035957, -0.016950570046901703, -0.009409273974597454, -0.024507876485586166, -0.014196636155247688, -0.0022482455242425203, -0.005539890378713608, -0.029311250895261765, -0.024657316505908966, 0.026984283700585365, -0.04073260352015495, 0.03266293928027153, 0.009473319165408611, -0.023589899763464928, -0.02378203347325325, -0.015594951808452606, 0.015520232729613781, -0.006500564981251955, 0.005566575564444065, -0.008758150041103363, -0.01698259264230728, -0.016406187787652016, -0.039302267134189606, -0.002617838326841593, -0.010364611633121967, -0.004384412430226803, -0.00028836916317231953, 0.03402923047542572, 0.11195062100887299, -0.004541856236755848, -0.03398653492331505, 0.0024443832226097584, -0.044703394174575806, -0.03084832988679409, -0.029353946447372437, 0.019437650218605995, -0.0038720525335520506, 0.01602191850543022, -0.021028099581599236, -0.002793962135910988, -0.00715702585875988, 0.007962925359606743, 0.00883820652961731, 0.04224833473563194, 0.02655731700360775, -0.027133721858263016, -0.012264613062143326, -0.01449551247060299, 0.03710338845849037, 0.004136237781494856, 0.03584383800625801, 0.009265173226594925, -0.020803943276405334, -0.05230339616537094, 0.014047197997570038, 0.04250451549887657, 0.019352257251739502, -0.008966296911239624, 0.04999777674674988, 0.018071357160806656, 0.0006964891217648983, -0.05332811549305916, -0.035779792815446854, -0.03129664435982704, -0.044105641543865204, -0.016299447044730186, 0.01730281673371792, -0.02877754159271717, -0.005206322763115168, -0.011143825948238373, -0.02152978628873825, 0.023056190460920334, -0.005086238496005535, -0.06609441339969635, 0.014890456572175026, 0.006004216615110636, -0.030421363189816475, -0.015626974403858185, 0.021326977759599686, 0.062337107956409454, -0.012339332140982151, -0.04735058546066284, -0.026087652891874313, 0.01871180720627308, 0.01742023415863514, 0.017783155664801598, -0.03861911967396736, 0.0321078822016716, 0.013545512221753597, 0.014132590964436531, 0.012435398995876312, 0.00011691543477354571, 0.03484046831727028, 0.00626039644703269, 0.032193273305892944, 0.023739337921142578, -0.041180919855833054, 0.004085535649210215, -0.007514610420912504, -0.04028429090976715, -0.005342418327927589, 0.060970816761255264, -0.018594391644001007, 0.003522473620250821, -0.03212922811508179, -0.005120929330587387, -0.05230339616537094, 0.030357317999005318, -0.010658151470124722, -0.036078669130802155, 0.026237091049551964, -0.007429216988384724, 0.03548091650009155, 0.0233337190002203, -0.01805000938475132, 0.02352585457265377, -0.013225287199020386, -0.005241014063358307, 0.02474270947277546, 0.021882032975554466, -0.011528095230460167, 0.008203093893826008, 0.0018773183692246675, 0.023355068638920784, 0.009201128035783768, 0.011560117825865746, -0.00038193489308469, 0.010738207958638668, 0.03059214912354946, -0.009932308457791805, 0.01300112996250391, 0.047137100249528885, -0.006447194144129753, -0.013449444435536861, 0.013460119254887104, 0.0159792210906744, 0.0010413980344310403, -0.024657316505908966, 0.028265181928873062, 0.0005373773747123778, -0.012157871387898922, 0.023717990145087242, 0.002360324142500758, -0.007253093644976616, 0.028820239007472992, -0.01701461523771286, 0.01201910711824894, 0.01823147013783455, -0.00328764203004539, -0.006281744688749313, 0.0017011946765705943, -0.040625862777233124, -0.01730281673371792, -0.0019907313399016857, 0.009825566783547401, -0.0050488789565861225, -0.03727417439222336, 0.0066446661949157715, 0.006516576278954744, -0.05029665306210518, 0.03588653355836868, -0.012414051219820976, -0.0010127112036570907, 0.002484411234036088, -0.003605198347941041, 0.025980912148952484, 0.014292703941464424, 0.003271630732342601, 0.037786535918712616, -0.019651133567094803, 0.020537089556455612, -0.018626414239406586, 0.008747476153075695, -0.004979496821761131, -0.011378657072782516, -0.006794104352593422, 0.02858540788292885, -0.028435969725251198, -0.01066882535815239, -0.003031462198123336, 0.06430115550756454, -0.0045765470713377, 0.03148877993226051, 0.007178374566137791, 0.019950009882450104, -0.004405760671943426, -0.005086238496005535, -0.014794389717280865, 0.020248886197805405, 0.0005540557322092354, 0.008389892056584358, 0.02403821423649788, -0.01675843447446823, -0.011314612813293934, -0.007808149792253971, 0.03842698410153389, -0.015893828123807907, 0.025169676169753075, -0.027155069634318352, -0.001188834896311164, 0.021241582930088043, -0.03189439699053764, 0.011047758162021637, 0.0186050646007061, 0.047948338091373444, 0.022543830797076225, 0.01641686260700226, -0.017217423766851425, 0.007429216988384724, 0.0012168545508757234, 0.013139894232153893, -0.019800571724772453, 0.038042716681957245, 0.005603935569524765, 0.023461809381842613, 0.004216294270008802, -0.028009003028273582, -0.01066882535815239, 0.0025337792467325926, -0.00501151941716671, 0.01249944418668747, -0.020291583612561226, 0.019181469455361366, 0.021145517006516457, -0.01264888234436512, -0.02811574377119541, -0.00024750715238042176, 0.016587648540735245, 0.023696640506386757, 0.030720239505171776, 0.010236522182822227, -0.01731349155306816, -0.010572758503258228, 0.012253938242793083, 0.012467421591281891, 0.01801798678934574, -0.0033036533277481794, 0.014207310043275356, -0.013406747952103615, -0.056573063135147095, -0.04419103264808655, -0.005134272389113903, -0.0068207900039851665, 0.007594666909426451, 0.0029300577007234097, -0.035267435014247894, -0.047478675842285156, 0.04457530379295349, -0.011464050970971584, 0.022992147132754326, 0.0015170653350651264, 0.016096636652946472, 0.06997980922460556, 0.03953709825873375, 0.0106528140604496, 0.021177537739276886, 0.00018846568127628416, 0.028094395995140076, -0.008619386702775955, 0.03362361341714859, -0.0035891872830688953, 0.035822488367557526, 0.037359569221735, -0.01083427481353283, 0.0004289679054636508, 0.0055132051929831505, 0.011400005780160427, 0.007471913937479258, -0.012072477489709854, 0.047435980290174484, 0.018850570544600487, 0.042184289544820786, -0.02747529372572899, 0.04645395651459694, -0.0009700145456008613, 0.011741578578948975, -0.05285845324397087, 0.01649158075451851, 0.03610001876950264, 0.023611247539520264, 0.029311250895261765, 0.011015735566616058, 0.014346074312925339, -0.012478096410632133, 0.02877754159271717, 0.01815675012767315, 0.023162933066487312, -0.011677534319460392, -0.018060682341456413, -0.004146912135183811, 0.0014423462562263012, 0.01499719824641943, 0.03612136468291283, 0.012211241759359837, 0.00950534176081419, -0.0031755634117871523, 0.03353821858763695, 0.008774161338806152, -0.006548598874360323, -0.009777532890439034, -0.03174496069550514, -0.0023162933066487312, -0.010380622930824757, 0.007914891466498375, -0.028713498264551163, 0.007076969835907221, -0.013780344277620316, -0.007941576652228832, -0.01734551414847374, 0.014676973223686218, 0.011581466533243656, -0.043806761503219604, 0.04389215633273125, -0.02581012435257435, 0.03283372521400452, -0.013545512221753597, -0.0015210681594908237, -0.005657306406646967, -0.006239048205316067, 0.033495523035526276, 0.009798881597816944, -0.014282029122114182, -0.030357317999005318, 0.0180820319801569, 0.005486519541591406, -0.020312931388616562, 0.014217984862625599, -0.002125492552295327, -0.002314958954229951, -0.003890732303261757, -0.018316863104701042, 0.015317423269152641, 0.05785395950078964, -0.0015170653350651264, 0.009958993643522263, -0.0025457877200096846, -0.030207879841327667, 0.008021633140742779, 0.05495058745145798, -0.011560117825865746, -0.007701408118009567, -0.010578094981610775, -0.012414051219820976, -0.024251697584986687, 0.011453376151621342, 0.019362930208444595, -0.0080269705504179, -0.0325561948120594, 0.0012328657321631908, -0.01752697490155697, -0.010199162177741528, 0.010583432391285896, -0.03172361105680466, 0.01237135473638773, 0.03846968337893486, -0.00023649941431358457, -0.005241014063358307, 0.006105620879679918, 0.02555394545197487, -0.003522473620250821, 0.010551409795880318, -0.014410119503736496, 0.009980342350900173, 0.010060397908091545, -0.005534553434699774, 0.017953941598534584, -0.04039103165268898, 0.01431405171751976, 0.019555065780878067, 0.048759575933218, 0.009387926198542118, 0.011933714151382446, -0.012253938242793083, 0.023141585290431976, -0.048759575933218, 0.0007298458949662745, -0.03624945506453514, 0.010748881846666336, 0.009905623272061348, 0.004758007824420929, 0.013214613310992718, 0.00010390629904577509, -0.01749495230615139, -0.028841586783528328, 0.015029220841825008, 0.012723601423203945, -0.0001839625183492899, 0.024273045361042023, 0.0033730354625731707, -0.00208012736402452, -0.02093203365802765, -0.004931462928652763, 0.0009540033061057329, -0.014751692302525043, -0.03588653355836868, -0.025276416912674904, -0.0048674182035028934, 0.0091904541477561, 0.006970228161662817, -0.030165184289216995, 0.019704503938555717, 0.007391857448965311, -0.016246074810624123, 0.008726128377020359, 0.02548990026116371, -0.03084832988679409, -0.058494411408901215, 0.0033009848557412624, -0.040476422756910324, -0.019426975399255753, 0.01532809715718031, -0.006505901925265789, 0.03539552167057991, -0.029909003525972366, 0.012937084771692753, -0.0366123765707016, -0.019661808386445045, 0.026386529207229614, 0.0071196663193404675, -0.05234609171748161, 0.017025290057063103, -0.027731474488973618, 0.04444721341133118, 0.028307879343628883, -0.006783430464565754, -0.005241014063358307, 0.0183809082955122, 0.010551409795880318, 0.049869686365127563, -0.00501151941716671, 0.011282590217888355, 0.004515170585364103, 0.0094893304631114, -0.0010207168525084853, 0.02862810343503952, -0.024144954979419708, 0.024764057248830795, -0.02807304821908474, 0.004109552595764399, 0.021326977759599686, -0.01890394277870655, 0.0287348460406065, 0.02097472921013832, -0.003034130670130253, -0.0028019677847623825, 0.04833260923624039, 0.010748881846666336, 0.027048328891396523, -0.017398884519934654, 0.0030394678469747305, 0.005886800587177277, -0.0043924180790781975, -0.0033490185160189867, 0.02474270947277546, 0.02999439649283886, 0.0007004919461905956, 0.03407192602753639, 0.01135730929672718, 0.017153378576040268, 0.018338210880756378, 0.028307879343628883, -0.0027085687033832073, 0.0001637816894799471, 0.03428541123867035, 0.039814624935388565, 0.004080198705196381, 0.02348315715789795, -0.042226988822221756, 0.004880760796368122, 0.016438210383057594, -0.0031488779932260513, 0.02230899967253208, -0.010247196070849895, -0.032791025936603546, 0.0052596936002373695, 0.0041442434303462505, 0.020099448040127754, 0.004536519292742014, -0.004699300043284893, -0.005822755862027407, -0.015594951808452606, 0.029311250895261765, 0.0041629234328866005, 0.02027023397386074, -0.03355956822633743, -0.0028046362567692995, -0.02877754159271717, 8.143218292389065e-05, -0.001072753337211907, 0.007578655611723661, -0.010973039083182812, -0.010962365195155144, -0.0010654148645699024, 0.004915452096611261, 0.023248326033353806, 0.0072904531843960285, -0.008384554646909237, -0.00674073351547122, -0.0079896105453372, 0.01315056812018156, 0.01686517708003521, 0.01333202887326479, 0.012595511972904205, -0.02559664100408554, -0.0024243691004812717, 0.03257754445075989, 0.006756744813174009, 0.006607306655496359, -0.005219665355980396, 0.036484286189079285, -0.03740226477384567, -0.03155282512307167, 0.004699300043284893, 0.02171124704182148, 0.015915175899863243, 0.017911244183778763, 0.03080563247203827, -0.02948203682899475, 0.00955871306359768, 0.002469734288752079, -0.005305058788508177, 0.010161803103983402, -0.013182590715587139, -0.013289332389831543, 0.01534944586455822, 0.025126978754997253, -0.0028339901473373175, -0.0068207900039851665, -0.01471967063844204, -0.014933153055608273, -0.01216854527592659, -0.010236522182822227, 0.026322485879063606, -0.02196742594242096, 0.015883153304457664, 0.012958433479070663, -0.02534046210348606, -0.004170929081737995, 0.029930351302027702, -0.015658996999263763, 0.020441021770238876, -0.030912375077605247, -0.001298912218771875, 0.008640734478831291, -0.011378657072782516, -0.0045792157761752605, -0.01886124536395073, -0.0057533737272024155, 0.001200843253172934, 0.0016811805544421077, 0.028051698580384254, -0.005107586737722158, 0.03505394980311394, 0.009868263266980648, 0.009121071547269821, -0.005732025485485792, 0.002368329791352153, 0.0074078687466681, 0.023568550124764442, -0.027389900758862495, 0.01098371297121048, -0.009660117328166962, 0.02444383315742016, -0.0005420473171398044, 0.006153654772788286, 0.00948399305343628, 0.017761806026101112, 0.024507876485586166, -0.0027832877822220325, 0.00830449815839529, -0.006463205441832542, 0.008998319506645203, 0.017110683023929596, -0.0030875015072524548, 0.03387979045510292, -0.010631466284394264, -0.017292143777012825, -0.04229103401303291, 0.02067585289478302, -0.01383371464908123, 0.020739898085594177, -0.006484553683549166, 0.027646081522107124, -0.02045169472694397, 0.043294403702020645, -0.0020134139340370893, -0.014773041009902954, -0.01697191782295704, 0.03336743265390396, 0.02041967213153839, 0.009249161928892136, 0.035822488367557526, -0.006297755986452103, -0.007429216988384724, -0.004032164812088013, -0.03174496069550514, 0.05815283954143524, -0.0024470516946166754, -0.018701132386922836, 0.03189439699053764, 0.03443484753370285, -0.0016745092580094934, 0.014911805279552937, -0.0038186816964298487, -0.014132590964436531, -0.004277670755982399, -0.00466194050386548, -0.016662368550896645, -0.019661808386445045, 0.07390790432691574, 0.007429216988384724, 0.016395512968301773, -0.0037759849801659584, 0.047478675842285156, -0.003020788077265024, 0.03355956822633743, 0.038298893719911575, 0.028158441185951233, 0.005555901676416397, 0.00029704193002544343, 0.013086522929370403, -0.01949102059006691, -0.013844388537108898, 0.030015746131539345, -0.003546490566805005, -0.03740226477384567, 0.03439215198159218, -0.02837192453444004, 0.011111803352832794, -0.0005253689596429467, -0.021903380751609802, 0.016075288876891136, -0.0029834285378456116, -0.006057587452232838, -0.018434278666973114, -0.01348146703094244, -0.014388770796358585, -0.023653944954276085, 0.024209000170230865, -0.0014983855653554201, 0.026535967364907265, 0.0027219115290790796, 0.027453945949673653, -0.02726181037724018, 0.00038660483551211655, -0.02041967213153839, -0.0236325953155756, -0.020334279164671898, -0.014250007458031178, -0.003004776779562235, 0.0022749309428036213, 0.008763487450778484, 0.003103512804955244, 0.0019280206179246306, -0.016950570046901703, 0.0011367982951924205, 0.02141237072646618, -0.03669777140021324, -0.009580060839653015, -0.02049439214169979, -0.008021633140742779, 0.02178596518933773, 0.009681465104222298, -0.022202258929610252, 0.007253093644976616, -0.030271925032138824, -0.011218545027077198, -0.020761245861649513, 0.010823600925505161, -0.01668371632695198, 0.0039227548986673355, -0.04431912302970886, -0.013940456323325634, -0.02529776468873024, -0.006975565105676651, 0.007952251471579075, 0.009435960091650486, 0.005406463518738747, 0.01033792644739151, -0.005174300167709589, -0.02559664100408554, 0.008058993145823479, 0.026642709970474243, -0.00600955355912447, 0.016374165192246437, -0.010556747205555439, 0.017911244183778763, -0.0028580070938915014, 0.028201136738061905, 0.05144946277141571, 0.010492702014744282, 0.03460563346743584, -0.021134842187166214, 0.01586180552840233, 0.009750847704708576, 0.03883260488510132, -0.009638768620789051, -0.0057640476152300835, -0.008197756484150887, -0.0027566025964915752, 0.024700012058019638, 0.006372475065290928, -0.025255069136619568, 0.027197767049074173, 0.016854502260684967, 0.03917417675256729, 0.024166304618120193, 0.015584276989102364, 0.032492149621248245, -0.02452922612428665, -0.016107311472296715, -0.02423034980893135, -0.008960959501564503, -0.026621362194418907, -0.011303937993943691, 0.027283160015940666, -0.01035927515476942, -0.0478629432618618, -0.02685619331896305, 0.0013876411831006408, 0.005286379251629114, -0.00984157808125019, 0.01471967063844204, -0.00980421807616949, -0.028243834152817726, -0.009852251969277859, 0.014228658750653267, 0.03272698074579239, 0.007658711634576321, 0.012584838084876537, 0.010711521841585636, -1.2414968296070583e-05, 0.0015410822816193104, -0.0029967711307108402, 0.013780344277620316, -0.017377536743879318, -0.007898880168795586, -0.014794389717280865, 0.01683315448462963, -0.015445513650774956, -0.028500014916062355, -0.005337081383913755, 0.04722249507904053, -0.01650225557386875, 0.028692148625850677, -0.0059348344802856445, -0.022735966369509697, 0.00287134968675673, 0.029012374579906464, 0.02771012671291828, -0.02241574227809906, -0.007189048454165459, 0.031531475484371185, -0.0006070929812267423, -0.003970788326114416, 0.01287304051220417, -0.02174326963722706, 0.007616015151143074, -0.008283150382339954, 0.028158441185951233]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# \"text-embedding-3-small\"モデルで埋め込みインスタンスを作成\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "# 質問文を定義\n",
    "query = \"AWSのS3からデータを読み込むためのDocument loaderはありますか？\"\n",
    "# 質問文をベクトル化（埋め込みを取得）\n",
    "vector = embeddings.embed_query(query)\n",
    "# ベクトルの中身を表示\n",
    "print(len(vector))\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len=4\n",
      "metadata={'file_name': 'aws.mdx', 'file_path': 'docs/docs/integrations/providers/aws.mdx', 'file_type': '.mdx', 'source': 'docs/docs/integrations/providers/aws.mdx'}\n",
      "### AWS S3 Directory and File\n",
      "\n",
      ">[Amazon Simple Storage Service (Amazon S3)](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-folders.html)\n",
      "> is an object storage service.\n",
      ">[AWS S3 Directory](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-folders.html)\n",
      ">[AWS S3 Buckets](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingBucket.html)\n",
      "\n",
      "See a [usage example for S3DirectoryLoader](/docs/integrations/document_loaders/aws_s3_directory).\n",
      "\n",
      "See a [usage example for S3FileLoader](/docs/integrations/document_loaders/aws_s3_file).\n",
      "\n",
      "```python\n",
      "from langchain_community.document_loaders import S3DirectoryLoader, S3FileLoader\n",
      "```\n",
      "\n",
      "### Amazon Textract\n",
      "\n",
      ">[Amazon Textract](https://docs.aws.amazon.com/managedservices/latest/userguide/textract.html) is a machine \n",
      "> learning (ML) service that automatically extracts text, handwriting, and data from scanned documents.\n",
      "\n",
      "See a [usage example](/docs/integrations/document_loaders/amazon_textract).\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# ドキュメントと埋め込みモデルからChromaベクトルストアを作成\n",
    "db = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "# ベクトルストアからレトリバー（検索用インターフェース）を作成\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# 質問文を定義\n",
    "query = \"AWSのS3からデータを読み込むためのDocument loaderはありますか？\"\n",
    "\n",
    "# レトリバーを使って関連ドキュメントを検索\n",
    "context_docs = retriever.invoke(query)\n",
    "# 検索結果のドキュメント数を表示\n",
    "print(f\"len={len(context_docs)}\")\n",
    "\n",
    "# 最初の検索結果ドキュメントを取得\n",
    "first_doc = context_docs[0]\n",
    "# 最初のドキュメントのメタデータを表示\n",
    "print(f\"metadata={first_doc.metadata}\")\n",
    "# 最初のドキュメントの本文を表示\n",
    "print(first_doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL を使った RAG の Chain の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "はい、AWSのS3からデータを読み込むためのDocument loaderとして、`S3DirectoryLoader`と`S3FileLoader`があります。これらは、AWS S3のディレクトリやファイルからデータを読み込むために使用されます。\n"
     ]
    }
   ],
   "source": [
    "# ChatPromptTemplateをインポート（プロンプトテンプレート作成用）\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# ChatOpenAIをインポート（OpenAIのチャットモデル利用用）\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# プロンプトテンプレートを作成（文脈と質問を埋め込む）\n",
    "prompt = ChatPromptTemplate.from_template('''\\\n",
    "以下の文脈だけを踏まえて質問に回答してください。\n",
    "\n",
    "文脈\"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "質問:{question}\n",
    "''')\n",
    "\n",
    "# OpenAIのチャットモデル（gpt-4o-mini）を初期化（温度0で出力の一貫性を高める）\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# StrOutputParserをインポート（モデル出力を文字列としてパースするため）\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# RunnablePassthroughをインポート（入力値をそのまま渡すため）\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# チェーンを構築（retrieverで文脈取得→プロンプト→モデル→出力パース）\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# チェーンにクエリを渡して実行し、結果を取得\n",
    "output = chain.invoke(query)\n",
    "# 結果を表示\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
