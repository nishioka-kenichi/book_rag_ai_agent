{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. OpenAI の チャット API の基礎\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 入出力の長さの制限や料金に影響する「トークン」\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トークン\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiktoken のインストール（Python 3.12以下で実行してください）\n",
    "# Python 3.13を使用している場合は、このセルをスキップしてください\n",
    "# !pip install tiktoken==0.7.0  # setup.shで事前インストール済み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat\n",
      "GPT\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "text = \"ChatGPT\"\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens = encoding.encode(text)\n",
    "for token in tokens:\n",
    "    print(encoding.decode([token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer と tiktoken の紹介\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "text = \"LLMを使ってクールなものを作るのは簡単だが、プロダクションで使えるものを作るのは非常に難しい。\"\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens = encoding.encode(text)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Chat Completions API を試す環境の準備\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI の API キーの準備\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "現在の作業ディレクトリ: /Users/kenichi/Projects\n",
      "参照する.envパス: /Users/kenichi/Projects/rag_ai_agent_book/.env\n",
      "OPENAI_API_KEY が正常に設定されました。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .envファイルのパスを明示的に指定\n",
    "# このノートブックが実行されているディレクトリに関わらず、\n",
    "# プロジェクトルートのrag_ai_agent_bookディレクトリにある.envファイルを指定\n",
    "current_working_directory = os.getcwd()\n",
    "# os.getcwd()が/Users/kenichi/Projects/を返すので、そこからrag_ai_agent_book/.envへのパスを構築\n",
    "dotenv_path = os.path.join(current_working_directory, 'rag_ai_agent_book', '.env')\n",
    "\n",
    "print(f\"現在の作業ディレクトリ: {current_working_directory}\")\n",
    "print(f\"参照する.envパス: {dotenv_path}\")\n",
    "\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "# 環境変数がロードされたか確認し、必要であればos.environに設定\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key is None:\n",
    "    print(\"OPENAI_API_KEY 環境変数が設定されていません。\")\n",
    "    print(\"rag_ai_agent_book/ディレクトリに.envファイルを作成し、OpenAI APIキーを設定してください。\")\n",
    "    print(\"例: OPENAI_API_KEY=\\\"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\\\"\")\n",
    "else:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key # 他のライブラリがos.environから直接読み込むことを期待する場合のために設定\n",
    "    print(\"OPENAI_API_KEY が正常に設定されました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Chat Completions API のハンズオン\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI のライブラリ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【注意】既知のエラーについて\n",
    "\n",
    "openai パッケージが依存する httpx のアップデートにより、`openai==1.40.6` を使用する箇所で `TypeError: Client.__init__() got an unexpected keyword argument 'proxies'` というエラーが発生するようになりました。\n",
    "\n",
    "このエラーは、`!pip install httpx==0.27.2` のように、httpx の特定バージョンをインストールすることで回避することができます。\n",
    "\n",
    "なお、Google Colab で一度上記のエラーに遭遇したあとで `!pip install httpx==0.27.2` のようにパッケージをインストールし直した場合、以下のどちらかの操作を実施する必要があります。\n",
    "\n",
    "- Google Colab の「ランタイム」から「セッションを再起動する」を実行する\n",
    "- 「ランタイムを接続解除して削除」を実行してパッケージのインストールからやり直す\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai==1.40.6 httpx==0.27.2  # setup.shで事前インストール済み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Completions API の呼び出し\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-BqJJ00f29LJocghFnUjTrhvesA12E\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"こんにちは、ジョンさん！お会いできて嬉しいです。何かお手伝いできることがありますか？\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"annotations\": []\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1751806966,\n",
      "    \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 27,\n",
      "        \"prompt_tokens\": 25,\n",
      "        \"total_tokens\": 52,\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"cached_tokens\": 0,\n",
      "            \"audio_tokens\": 0\n",
      "        },\n",
      "        \"completion_tokens_details\": {\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"こんにちは！私はジョンと言います！\"},\n",
    "    ],\n",
    ")\n",
    "print(response.to_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 会話履歴を踏まえた応答を得る\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-Bq8XX1O4VIF7dQqduHTRGDhtlp2vQ\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"はい、あなたの名前は西岡さんです。何かお手伝いできることがあれば教えてください！\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1751765583,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 27,\n",
      "    \"prompt_tokens\": 68,\n",
      "    \"total_tokens\": 95,\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"cached_tokens\": 0,\n",
      "      \"audio_tokens\": 0\n",
      "    },\n",
      "    \"completion_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"こんにちは！私は西岡と言います！\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"こんにちは、西岡さん！お会いできて嬉しいです。今日はどんなことをお話ししましょうか？\"},\n",
    "        {\"role\": \"user\", \"content\": \"私の名前が分かりますか？\"},\n",
    "    ],\n",
    ")\n",
    "print(response.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ストリーミングで応答を得る\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは、西岡さん！お会いできて嬉しいです。今日はどのようなことについてお話ししましょうか？"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"こんにちは！私は西岡と言います！\"},\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON モード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"people\": [\"おじいさん\", \"おばあさん\"]}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '人物一覧を次のJSON形式で出力してください。\\n{\"people\": [\"aaa\", \"bbb\"]}',\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"昔々あるところにおじいさんとおばあさんがいました\",\n",
    "        },\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision（画像入力）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "この画像は本の表紙を示しています。タイトルは「ChatGPT/LangChainによるチャットシステム構築【実践】入門」で、著者名が記載されています。表紙にはカラフルな鳥のイラストが描かれており、背景は明るい色合いです。また、「ChatGPT」という文字が大きく表示されており、内容に関連した情報が書かれています。本書は、AIモデルやシステム構築に関する知識や実践的なガイドを提供しているようです。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "image_url = \"https://raw.githubusercontent.com/yoshidashingo/langchain-book/main/assets/cover.jpg\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"画像を説明してください。\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （コラム）Completions API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"cmpl-BqJPaLaClCSMOL77LtJcsKK6pVC7Y\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"length\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"');\\n        followUp(event, inputText.text);\\n      }\\n      break;\\n \"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1751807374,\n",
      "  \"model\": \"gpt-3.5-turbo-instruct:20230824-v2\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 16,\n",
      "    \"prompt_tokens\": 11,\n",
      "    \"total_tokens\": 27\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"こんにちは！私はジョンと言います！\",\n",
    ")\n",
    "print(response.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Function calling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function calling のサンプルコード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps(\n",
    "            {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit}\n",
    "        )\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function callingで使用するツールの定義\n",
    "# OpenAIのFunction calling機能では、JSON Schema形式で関数の仕様を定義する\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",  # ツールの種類を指定（function calling）\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",  # 呼び出したい関数名\n",
    "            \"description\": \"指定された場所の現在の天気を取得する\",  # 関数の説明（LLMが関数を理解するために使用）\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",  # パラメータの型（JSON Schema形式）\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",  # パラメータの型\n",
    "                        \"description\": \"都市と州、例：San Francisco, CA\",  # パラメータの説明\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"]  # 選択可能な値の制限\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],  # 必須パラメータの指定\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-BqJPawLNehB5DSD5HLsl3PHWYho32\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"tool_calls\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"tool_calls\": [\n",
      "                    {\n",
      "                        \"id\": \"call_aaafNN2zCZTriNApCR2kOU2V\",\n",
      "                        \"function\": {\n",
      "                            \"arguments\": \"{\\\"location\\\":\\\"Tokyo, Japan\\\"}\",\n",
      "                            \"name\": \"get_current_weather\"\n",
      "                        },\n",
      "                        \"type\": \"function\"\n",
      "                    }\n",
      "                ],\n",
      "                \"annotations\": []\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1751807374,\n",
      "    \"model\": \"gpt-4o-2024-08-06\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"system_fingerprint\": \"fp_07871e2ad8\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 17,\n",
      "        \"prompt_tokens\": 84,\n",
      "        \"total_tokens\": 101,\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"cached_tokens\": 0,\n",
      "            \"audio_tokens\": 0\n",
      "        },\n",
      "        \"completion_tokens_details\": {\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"東京の天気はどうですか？\"},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "print(response.to_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '東京の天気はどうですか？'}, {'content': None, 'refusal': None, 'role': 'assistant', 'tool_calls': [{'id': 'call_aaafNN2zCZTriNApCR2kOU2V', 'function': {'arguments': '{\"location\":\"Tokyo, Japan\"}', 'name': 'get_current_weather'}, 'type': 'function'}], 'annotations': []}]\n"
     ]
    }
   ],
   "source": [
    "response_message = response.choices[0].message\n",
    "messages.append(response_message.to_dict())\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": null}\n"
     ]
    }
   ],
   "source": [
    "available_functions = {\n",
    "    \"get_current_weather\": get_current_weather,\n",
    "}\n",
    "\n",
    "# 使いたい関数は複数あるかもしれないのでループ\n",
    "for tool_call in response_message.tool_calls:\n",
    "    # 関数を実行\n",
    "    function_name = tool_call.function.name\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    function_response = function_to_call(\n",
    "        location=function_args.get(\"location\"),\n",
    "        unit=function_args.get(\"unit\"),\n",
    "    )\n",
    "    print(function_response)\n",
    "\n",
    "    # 関数の実行結果を会話履歴としてmessagesに追加\n",
    "    messages.append(\n",
    "        {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"東京の天気はどうですか？\"\n",
      "  },\n",
      "  {\n",
      "    \"content\": null,\n",
      "    \"refusal\": null,\n",
      "    \"role\": \"assistant\",\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"id\": \"call_aaafNN2zCZTriNApCR2kOU2V\",\n",
      "        \"function\": {\n",
      "          \"arguments\": \"{\\\"location\\\":\\\"Tokyo, Japan\\\"}\",\n",
      "          \"name\": \"get_current_weather\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      }\n",
      "    ],\n",
      "    \"annotations\": []\n",
      "  },\n",
      "  {\n",
      "    \"tool_call_id\": \"call_aaafNN2zCZTriNApCR2kOU2V\",\n",
      "    \"role\": \"tool\",\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"content\": \"{\\\"location\\\": \\\"Tokyo\\\", \\\"temperature\\\": \\\"10\\\", \\\"unit\\\": null}\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(messages, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-BqJPfx7lnA1zJ04PV4klYIXdr21mm\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"東京の現在の気温は約10度です。具体的な天気の状態（晴れ、雨、曇りなど）はわかりませんが、全般的にこの時期は涼しいので、暖かい服装がおすすめです。\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1751807379,\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_a288987b44\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 58,\n",
      "    \"prompt_tokens\": 59,\n",
      "    \"total_tokens\": 117,\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"cached_tokens\": 0,\n",
      "      \"audio_tokens\": 0\n",
      "    },\n",
      "    \"completion_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "second_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(second_response.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
