{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. LangSmith を使った RAG アプリケーションの評価\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:34.489407Z",
     "iopub.status.busy": "2024-06-28T02:32:34.488775Z",
     "iopub.status.idle": "2024-06-28T02:32:34.491583Z",
     "shell.execute_reply": "2024-06-28T02:32:34.491086Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "dotenv_path = os.path.join(os.getcwd(), 'rag_ai_agent_book', '.env')\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"rag-ai-agent-book\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. Ragas による合成テストデータの生成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パッケージのインストール\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-core==0.2.30 langchain-openai==0.1.21 \\\n",
    "#     langchain-community==0.2.12 GitPython==3.1.43 \\\n",
    "#     langchain-chroma==0.1.2 chromadb==0.5.3 \\\n",
    "#     ragas==0.1.14 nest-asyncio==1.6.0 pydantic==2.10.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検索対象のドキュメントのロード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import GitLoader  # Gitリポジトリからドキュメントをロードするためのクラスをインポート\n",
    "\n",
    "# .mdxファイルのみを対象とするフィルタ関数を定義\n",
    "def file_filter(file_path: str) -> bool:\n",
    "    # ファイルパスが.mdxで終わる場合のみTrueを返す\n",
    "    return file_path.endswith(\".mdx\")\n",
    "\n",
    "# GitLoaderのインスタンスを作成し、リポジトリからドキュメントをロードする準備をする\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/langchain-ai/langchain\",  # クローンするGitリポジトリのURL\n",
    "    repo_path=\"./langchain\",  # ローカルにクローンするパス\n",
    "    branch=\"master\",  # チェックアウトするブランチ名\n",
    "    file_filter=file_filter,  # 使用するファイルフィルタ関数\n",
    ")\n",
    "\n",
    "# ドキュメントをロードし、リストとして取得\n",
    "documents = loader.load()\n",
    "# ロードしたドキュメント数を出力\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragas による合成テストデータ生成の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各ドキュメントのメタデータに\"filename\"キーを追加し、\"source\"の値をコピーする\n",
    "for document in documents:  # documentsリスト内の各ドキュメントに対して処理を行う\n",
    "    document.metadata[\"filename\"] = document.metadata[\"source\"]  # \"source\"の値を\"filename\"キーに設定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb6e68119f3416d89ee4d513de926b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/1296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd15ea3087d643138ecb1b0d605297b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nest_asyncio  # Jupyter環境などで非同期処理の競合を防ぐためのパッケージ\n",
    "from ragas.testset.generator import TestsetGenerator  # Ragasのテストセット生成クラスをインポート\n",
    "from ragas.testset.evolutions import simple,reasoning,multi_context  # テストデータ生成時の進化タイプをインポート\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # OpenAIのチャットモデルと埋め込みモデルをインポート\n",
    "\n",
    "# Jupyterなどの環境でasyncioのイベントループの競合を回避する\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# テストセット生成器を初期化する\n",
    "generator=TestsetGenerator.from_langchain(\n",
    "    generator_llm=ChatOpenAI(model=\"gpt-4o-mini\"),  # 質問生成用のLLMを指定\n",
    "    critic_llm=ChatOpenAI(model=\"gpt-4o-mini\"),     # 評価用のLLMを指定\n",
    "    embeddings=OpenAIEmbeddings(),                  # 埋め込みモデルを指定\n",
    ")\n",
    "\n",
    "# LangChainのドキュメントからテストセットを生成する\n",
    "testset=generator.generate_with_langchain_docs(\n",
    "    documents,  # テストデータ生成対象のドキュメント\n",
    "    test_size=6,  # 生成するテストデータ数\n",
    "    distributions={simple:0.5,reasoning:0.25,multi_context:0.25}  # 各進化タイプの割合を指定\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of RAG evaluation in the c...</td>\n",
       "      <td>[# Vectorize\\n\\n&gt; [Vectorize](https://vectoriz...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the significance of interoperability i...</td>\n",
       "      <td>[---\\npagination_prev: null\\npagination_next: ...</td>\n",
       "      <td>Interoperability in LangChain components is si...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'docs/docs/contributing/how_to/int...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of Datadog in the context ...</td>\n",
       "      <td>[# Datadog Logs\\n\\n&gt;[Datadog](https://www.data...</td>\n",
       "      <td>Datadog is a monitoring and analytics platform...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What enables easy component swaps in LangChain...</td>\n",
       "      <td>[---\\npagination_prev: null\\npagination_next: ...</td>\n",
       "      <td>LangChain components expose a standard interfa...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'docs/docs/contributing/how_to/int...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What’s needed for Banana's GPU inference?</td>\n",
       "      <td>[# Banana\\n\\n&gt;[Banana](https://www.banana.dev/...</td>\n",
       "      <td>To use Banana's GPU inference, you need to ins...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does LangChain's standard interface help d...</td>\n",
       "      <td>[---\\npagination_prev: null\\npagination_next: ...</td>\n",
       "      <td>LangChain's standard interface helps developer...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'docs/docs/contributing/how_to/int...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does langchain-robocorp aid Python workers...</td>\n",
       "      <td>[# Sema4 (fka Robocorp)\\n\\n&gt;[Robocorp](https:/...</td>\n",
       "      <td>The context does not provide specific informat...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  ... episode_done\n",
       "0  What is the purpose of RAG evaluation in the c...  ...         True\n",
       "1  What is the significance of interoperability i...  ...         True\n",
       "2  What is the purpose of Datadog in the context ...  ...         True\n",
       "3  What enables easy component swaps in LangChain...  ...         True\n",
       "4          What’s needed for Banana's GPU inference?  ...         True\n",
       "5  How does LangChain's standard interface help d...  ...         True\n",
       "6  How does langchain-robocorp aid Python workers...  ...         True\n",
       "\n",
       "[7 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストセットの中身確認\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith の Dataset の作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client  # LangSmithのClientクラスをインポートし、データセット管理を行う\n",
    "\n",
    "# データセット名を定義\n",
    "dataset_name = \"agent-book\"  # 作成・削除対象となるデータセット名を指定\n",
    "\n",
    "# LangSmithクライアントのインスタンスを作成\n",
    "client = Client()  # API操作用のクライアントを初期化\n",
    "\n",
    "# 既存の同名データセットが存在する場合は削除する\n",
    "if client.has_dataset(dataset_name=dataset_name):  # 指定した名前のデータセットが存在するか確認\n",
    "    client.delete_dataset(dataset_name=dataset_name)  # 存在する場合はデータセットを削除\n",
    "\n",
    "# 新しいデータセットを作成する\n",
    "dataset = client.create_dataset(dataset_name=dataset_name)  # 指定した名前で新規データセットを作成し、変数に格納\n",
    "\n",
    "# LangSmithでデータセットを確認する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合成テストデータの保存\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力データ、出力データ、メタデータを格納するリストを初期化\n",
    "inputs=[]  # 各テストセットの入力（質問）を格納するリスト\n",
    "outputs=[]  # 各テストセットの出力（コンテキストと正解）を格納するリスト\n",
    "metadatas=[]  # 各テストセットのメタデータ（ソースや進化タイプ）を格納するリスト\n",
    "\n",
    "# テストセットの各レコードを処理し、必要な情報をリストに追加\n",
    "for testset_record in testset.test_data:  # testsetの各テストデータを1件ずつ処理\n",
    "\t# 質問文をinputsリストに追加\n",
    "\tinputs.append(  # inputsリストに辞書を追加\n",
    "\t\t{\n",
    "\t\t\t\"question\":testset_record.question,  # 質問文を格納\n",
    "\t\t}\n",
    "\t)\n",
    "\t# コンテキストと正解をoutputsリストに追加\n",
    "\toutputs.append(  # outputsリストに辞書を追加\n",
    "\t\t{\n",
    "\t\t\t\"contexts\":testset_record.contexts,  # 関連コンテキストを格納\n",
    "\t\t\t\"ground_truth\":testset_record.ground_truth  # 正解（期待される回答）を格納\n",
    "\t\t}\n",
    "\t)\n",
    "\t# ソースと進化タイプをmetadatasリストに追加\n",
    "\tmetadatas.append(  # metadatasリストに辞書を追加\n",
    "\t\t{\n",
    "\t\t\t\"source\":testset_record.metadata[0][\"source\"],  # ドキュメントのソース情報を格納\n",
    "\t\t\t\"evolution_type\":testset_record.evolution_type  # 進化タイプを格納\n",
    "\t\t}\n",
    "\t)\n",
    "\n",
    "# 収集したinputs, outputs, metadatasを使ってLangSmithに例を一括登録\n",
    "client.create_examples(  # LangSmithのデータセットに例を一括作成\n",
    "\tinputs=inputs,  # 入力データ（質問リスト）\n",
    "\toutputs=outputs,  # 出力データ（コンテキストと正解リスト）\n",
    "\tmetadata=metadatas,  # メタデータ（ソース・進化タイプリスト）\n",
    "\tdataset_id=dataset.id  # 対象データセットのID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. LangSmith と Ragas を使ったオフライン評価の実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カスタム Evaluator の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any  # typingモジュールからAny型をインポート。型ヒントで任意の型を指定するために使用。\n",
    "from langchain_core.embeddings import Embeddings  # langchain_core.embeddingsからEmbeddingsクラスをインポート。埋め込みモデルの型指定用。\n",
    "from langchain_core.language_models import BaseChatModel  # langchain_core.language_modelsからBaseChatModelをインポート。チャットモデルの基底クラス。\n",
    "from langsmith.schemas import Example, Run  # langsmith.schemasからExampleとRunをインポート。評価対象の例と実行結果のスキーマ。\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper  # ragas.embeddingsからLangchainEmbeddingsWrapperをインポート。LangChainの埋め込みをRagas用にラップ。\n",
    "from ragas.llms import LangchainLLMWrapper  # ragas.llmsからLangchainLLMWrapperをインポート。LangChainのLLMをRagas用にラップ。\n",
    "from ragas.metrics.base import Metric, MetricWithEmbeddings, MetricWithLLM  # ragas.metrics.baseから評価指標の基底クラスと埋め込み/LLM対応クラスをインポート。\n",
    "\n",
    "# Ragasの評価指標をLangSmith Evaluatorとして利用するためのラッパークラスを定義\n",
    "class RagasMetricEvaluator:\n",
    "    # 初期化メソッド。評価指標、LLM、埋め込みモデルを受け取る\n",
    "    def __init__(self, metric: Metric, llm: BaseChatModel, embeddings: Embeddings):\n",
    "        self.metric = metric  # 渡された評価指標をインスタンス変数に格納\n",
    "\n",
    "        # 評価指標がLLMを必要とする場合、LLMラッパーを設定\n",
    "        if isinstance(self.metric, MetricWithLLM):\n",
    "            self.metric.llm = LangchainLLMWrapper(llm)  # LLMをRagas用ラッパーで包んでセット\n",
    "        # 評価指標が埋め込みを必要とする場合、埋め込みラッパーを設定\n",
    "        if isinstance(self.metric, MetricWithEmbeddings):\n",
    "            self.metric.embeddings = LangchainEmbeddingsWrapper(embeddings)  # 埋め込みをRagas用ラッパーで包んでセット\n",
    "\n",
    "    # 評価メソッド。RunとExampleを受け取り、評価結果の辞書を返す\n",
    "    def evaluate(self, run: Run, example: Example) -> dict[str, Any]:\n",
    "        # Runから文脈（contexts）のテキストを抽出しリスト化\n",
    "        context_strs = [doc.page_content for doc in run.outputs[\"contexts\"]]\n",
    "\n",
    "        # Ragasの評価指標のscoreメソッドを呼び出してスコアを算出\n",
    "        score = self.metric.score(\n",
    "            {  # 評価に必要な情報を辞書で渡す\n",
    "                \"question\": example.inputs[\"question\"],  # 質問文\n",
    "                \"answer\": run.outputs[\"answer\"],  # モデルの回答\n",
    "                \"contexts\": context_strs,  # 関連文脈\n",
    "                \"ground_truth\": example.outputs[\"ground_truth\"],  # 正解\n",
    "            },  # 各要素を評価指標に渡す\n",
    "        )  # scoreメソッドでスコアを計算\n",
    "        return {\"key\": self.metric.name, \"score\": score}  # 評価指標名とスコアを辞書で返す\n",
    "\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # langchain_openaiからChatOpenAI（LLM）とOpenAIEmbeddings（埋め込みモデル）をインポート\n",
    "from ragas.metrics import answer_relevancy, context_precision  # ragas.metricsからanswer_relevancyとcontext_precisionの評価指標をインポート\n",
    "\n",
    "# 使用する評価指標をリストで定義\n",
    "metrics = [context_precision, answer_relevancy]  # 文脈精度と回答関連性\n",
    "\n",
    "# OpenAIのGPT-4oモデルをLLMとして初期化\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)  # gpt-4oモデルを温度0で生成\n",
    "\n",
    "# OpenAIのtext-embedding-3-smallモデルで埋め込みモデルを初期化\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # text-embedding-3-smallモデルで埋め込み生成\n",
    "\n",
    "# 各評価指標ごとにRagasMetricEvaluatorを生成し、evaluateメソッドをリスト化\n",
    "evaluators = [\n",
    "    RagasMetricEvaluator(metric, llm, embeddings).evaluate  # 各評価指標に対してEvaluatorを作成し、evaluateメソッドを取得\n",
    "    for metric in metrics  # metricsリスト内の各指標に対して処理\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論の関数の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma  # Chromaベースのベクトルストアを利用するためのクラスをインポート\n",
    "from langchain_openai import OpenAIEmbeddings  # OpenAIの埋め込みモデルを利用するためのクラスをインポート\n",
    "\n",
    "# OpenAIのtext-embedding-3-smallモデルを用いて埋め込みモデルを初期化\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # OpenAIEmbeddings: テキストをベクトル化するためのクラス\n",
    "\n",
    "# ドキュメント群からChromaベクトルストアを作成\n",
    "db = Chroma.from_documents(documents, embeddings)  # Chroma: ベクトルストア、from_documentsで初期化\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser  # StrOutputParser: LLM出力を文字列として扱う\n",
    "from langchain_core.prompts import ChatPromptTemplate  # ChatPromptTemplate: チャット用プロンプトのテンプレート化\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough  # RunnableParallel: 並列実行, RunnablePassthrough: 入力をそのまま渡す\n",
    "from langchain_openai import ChatOpenAI  # ChatOpenAI: OpenAIのチャットLLMを利用\n",
    "\n",
    "# プロンプトテンプレートを定義（複数行）\n",
    "prompt = ChatPromptTemplate.from_template('''\\\n",
    "以下の文脈だけを踏まえて質問に回答してください。\n",
    "文脈: \"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "質問: {question}\n",
    "''')  # テンプレート定義終了\n",
    "\n",
    "# gpt-4o-miniモデルを用いてLLMを初期化\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)  # ChatOpenAI: gpt-4o-miniモデルを温度0で生成\n",
    "\n",
    "# ベクトルストアからレトリバーを作成\n",
    "retriever = db.as_retriever()  # as_retriever: ベクトル検索用のレトリバーを取得\n",
    "\n",
    "# 推論チェーンを構築（複数行）\n",
    "chain = RunnableParallel(  # RunnableParallel: 並列に複数の処理を実行するチェーンを作成\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),  # \"question\"キーはそのまま渡す\n",
    "        \"context\": retriever,  # \"context\"キーにはレトリバーの出力を渡す\n",
    "    }\n",
    ").assign(answer=prompt | model | StrOutputParser())  # assignで\"answer\"キーにプロンプト→モデル→出力パーサの流れを設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オフライン評価の実装・実行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'crazy-history-69' at:\n",
      "https://smith.langchain.com/o/bebc8bb1-8ebf-49c3-8c20-fe0c2220db92/datasets/a5328057-4fa4-4330-a4c2-a7e4d3135c2f/compare?selectedSessions=61f77f30-69d0-41c3-9f6b-7f9a8736b5e4\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746a03c855aa4c12a8d0c699ef4eb5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run cff735a0-bf7b-4722-b8e0-aeecf0952fe5: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x30923fbf0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f545150c-1cc8-4d04-844c-6894d26ae012: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x3275e98b0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ac1df286-ce0b-445f-9e07-76683b50e528: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x30923c9b0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e2e1880b-6f3a-487f-9e9f-c55ed56956e9: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x30c0ddeb0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 10a2148c-7f23-447d-8679-ad11c59ddbcf: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x177c24d70 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f545150c-1cc8-4d04-844c-6894d26ae012: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x30c0dc890 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run dfdef843-fb11-4739-bd35-b61117431d57: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x30c1106b0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 07455090-977a-4f3c-868f-09203dd20267: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x30c1139b0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d12bc046-fe72-41f5-a2b0-b5d7ec734f53: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x177cc0950 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e85e100b-cae8-40fc-84ed-c5d9c9634137: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x3275e9d30 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run dfdef843-fb11-4739-bd35-b61117431d57: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x177b33410 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 10a2148c-7f23-447d-8679-ad11c59ddbcf: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x30923ce90 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d9e89900-2785-48ab-ae91-0078e70f4584: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x30c1110d0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 58996f6b-9b6b-4d21-b83c-fa32998fb191: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x177b338f0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f40c41b2-be80-4e5f-85d2-c646f0263554: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x3275439b0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 07455090-977a-4f3c-868f-09203dd20267: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x3275692b0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e2e1880b-6f3a-487f-9e9f-c55ed56956e9: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x327543d10 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ed5e635f-1d6e-484c-8b35-eb7ff6988860: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x177b32b70 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_context_precision.py\", line 152, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ed5e635f-1d6e-484c-8b35-eb7ff6988860: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x32756aed0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f40c41b2-be80-4e5f-85d2-c646f0263554: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x309078bf0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ac1df286-ce0b-445f-9e07-76683b50e528: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1548, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x32758cad0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "        run=run,\n",
      "        example=example,\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": source_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/sf/2870kdw54dbg3z6dyhtwdhwr0000gq/T/ipykernel_28140/1881934449.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "        {\n",
      "    ...<4 lines>...\n",
      "        },\n",
      "    )\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/metrics/_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<35 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1815, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1509, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1595, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1572, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kenichi/Projects/rag_ai_agent_book/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n"
     ]
    }
   ],
   "source": [
    "# 入力辞書から質問を受け取り、推論チェーンを実行して結果を返す関数を定義\n",
    "def predict(inputs: dict[str, Any]) -> dict[str, Any]:  # 入力と出力の型アノテーション付きで関数を定義\n",
    "    # 入力辞書から\"question\"キーの値（質問文）を取得\n",
    "    question = inputs[\"question\"]\n",
    "    # チェーンに質問を渡して推論を実行し、出力を取得\n",
    "    output = chain.invoke(question)\n",
    "    # 推論結果から文脈と回答を辞書形式で返す\n",
    "    return {\n",
    "        \"contexts\": output[\"context\"],  # 取得した文脈を\"contexts\"キーに格納\n",
    "        \"answer\": output[\"answer\"],     # 生成された回答を\"answer\"キーに格納\n",
    "    }\n",
    "\n",
    "\n",
    "from langsmith.evaluation import evaluate  # LangSmithの評価用関数をインポート\n",
    "\n",
    "# オフライン評価を実行する。predict関数を評価対象とし、データセットと評価指標を指定\n",
    "evaluate(\n",
    "    predict,            # 評価対象の関数\n",
    "    data=\"agent-book\",  # 使用するデータセット名\n",
    "    evaluators=evaluators,  # 使用する評価指標\n",
    ")\n",
    "\n",
    "# 評価結果の比較ページURL（参考用）\n",
    "# https://smith.langchain.com/o/bebc8bb1-8ebf-49c3-8c20-fe0c2220db92/datasets/a5328057-4fa4-4330-a4c2-a7e4d3135c2f/compare?selectedSessions=64b1006f-bbb9-474f-ac13-c5aedf271a8d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith を使ったオンライン評価の実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィードバックボタンを表示する関数の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID  # UUID型をインポート\n",
    "import ipywidgets as widgets  # ipywidgetsのwidgetsモジュールをインポート\n",
    "from IPython.display import display  # display関数をインポート\n",
    "from langsmith import Client  # LangSmithのClientクラスをインポート\n",
    "\n",
    "# フィードバック用のボタンを表示する関数を定義\n",
    "def display_feedback_buttons(run_id:UUID)->None:\n",
    "\t# 「Good」ボタンを作成\n",
    "\tgood_button=widgets.Button(\n",
    "\t\tdescription=\"Good\",  # ボタンのラベル\n",
    "\t\tbutton_style=\"success\",  # ボタンのスタイル\n",
    "\t\ticon=\"thumbs-up\"  # ボタンのアイコン\n",
    "\t)\n",
    "\t# 「Bad」ボタンを作成\n",
    "\tbad_button=widgets.Button(\n",
    "\t\tdescription=\"Bad\",  # ボタンのラベル\n",
    "\t\tbutton_style=\"danger\",  # ボタンのスタイル\n",
    "\t\ticon=\"thumbs-down\"  # ボタンのアイコン\n",
    "\t)\n",
    "\n",
    "\t# ボタンクリック時のコールバック関数を定義\n",
    "\tdef on_button_clicked(button:widgets.Button)->None:\n",
    "\t\t# クリックされたボタンがgood_buttonの場合\n",
    "\t\tif button==good_button:\n",
    "\t\t\tscore=1  # スコアを1に設定\n",
    "\t\t# クリックされたボタンがbad_buttonの場合\n",
    "\t\telif button==bad_button:\n",
    "\t\t\tscore=0  # スコアを0に設定\n",
    "\t\t# それ以外の場合はエラー\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(f\"Unknown button:{button}\")  # 未知のボタンエラー\n",
    "\n",
    "\t\t# LangSmithクライアントを作成\n",
    "\t\tclient=Client()\n",
    "\t\t# フィードバックを送信\n",
    "\t\tclient.create_feedback(run_id=run_id, key=\"thumbs\",score=score)\n",
    "\t\t# 送信完了メッセージを表示\n",
    "\t\tprint(\"フィードバックを送信しました\")\n",
    "\n",
    "\t# good_buttonにクリックイベントを登録\n",
    "\tgood_button.on_click(on_button_clicked)\n",
    "\t# bad_buttonにクリックイベントを登録\n",
    "\tbad_button.on_click(on_button_clicked)\n",
    "\n",
    "\t# 2つのボタンを表示\n",
    "\tdisplay(good_button, bad_button)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィードバックボタンを表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChainは、大規模言語モデル（LLM）を活用したアプリケーションを開発するためのフレームワークです。このフレームワークは、LLMアプリケーションのライフサイクルの各段階を簡素化します。具体的には、以下の3つの主要なステージがあります。\n",
      "\n",
      "1. **開発**: LangChainのオープンソースコンポーネントやサードパーティの統合を使用してアプリケーションを構築します。LangGraphを利用することで、状態を持つエージェントを構築し、ストリーミングや人間の介入をサポートします。\n",
      "\n",
      "2. **プロダクショナリゼーション**: LangSmithを使用してアプリケーションを検査、監視、評価し、継続的に最適化して自信を持ってデプロイできるようにします。\n",
      "\n",
      "3. **デプロイメント**: LangGraphアプリケーションをプロダクション対応のAPIやアシスタントに変換します。\n",
      "\n",
      "LangChainは、LLMや関連技術（埋め込みモデルやベクターストアなど）に対する標準インターフェースを実装し、数百のプロバイダーと統合しています。また、複数のオープンソースライブラリで構成されており、さまざまな統合パッケージやコミュニティによって維持されるコンポーネントが含まれています。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2711d55e0873477abcc1afb37d5e2f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Good', icon='thumbs-up', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734679db6a6643bcaa838f5c1b622315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Bad', icon='thumbs-down', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.tracers.context import collect_runs  # collect_runsをインポート\n",
    "\n",
    "# LangChainの実行をトレースし、出力とrun_idを取得\n",
    "with collect_runs() as runs_cb:\n",
    "\toutput=chain.invoke(\"LangChainの概要を教えて\")  # チェーンに質問を投げて出力を取得\n",
    "\tprint(output[\"answer\"])  # 回答部分のみ表示\n",
    "\trun_id=runs_cb.traced_runs[0].id  # 最初のrun_idを取得\n",
    "\n",
    "# フィードバックボタンを表示\n",
    "display_feedback_buttons(run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
